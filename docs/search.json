[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "母平均の推定",
    "section": "",
    "text": "Preface\n\\(X\\) 内での \\(Y\\) の平均値 (“条件つき”母平均)を推定する方法を紹介します。 母平均の推定値は、さまざまな実務で活用されており、特に予測問題において、最も代表的な予測値となります。\n伝統的にはOLSが、母平均の推定方法として用いられてきました。 近年では、機械学習の手法も積極的に活用されています。 本ノートでは、OLSが”研究者が設定した母平均のシンプルなモデル”を推定する方法として優れていることを強調します。 その後、“複雑なモデル”を推定する方法として、LASSOを紹介します1。",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#reference",
    "href": "index.html#reference",
    "title": "母平均の推定",
    "section": "Reference",
    "text": "Reference\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, et al. 2021. An Introduction to Statistical Learning. Vol. 112. Springer.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "母平均の推定",
    "section": "",
    "text": "他の予測モデルの推定方法については、James et al. (2021) 参照↩︎",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "1  要約の基本コンセプト",
    "section": "",
    "text": "1.1 観察できない変数が引き起こす問題\nデータから観察できない変数の存在は、あらゆる事例分析の最も深刻な問題の一つです。 このような変数への対処について、膨大な議論が蓄積されています。\n観察できない変数がもたらす問題は、個別事例分析において特に顕著です。 以下では、取引価格(Price; 単位 \\(=\\) 100万円) \\(=Y\\) と物件の特徴 \\(=X\\) の関係性を把握するために、個別事例を丹念に見ていきます。 例えば、以下の2億円で取引されている物件が、データの中に含まれていました。\nPrice\nSize\nTradeYear\nLargeDistrict\nTenure\n\n\n\n\n200\n105\n2022\n中心6区\n31\nこの事例から、部屋の広さが105平米で中心6区(港、中央、千代田、新宿、渋谷、文教)に立地する物件は、2億円で取引される傾向があったと結論づけても良いでしょうか？ ほとんどの応用でこのような推測は、不適切です。 実際に同じデータの中に、取引価格以外全く同じ特徴を持つ物件の取引事例が、以下の3件ありました。 これらの事例と比較すると、2億円はかなり高い価格での取引だったことがわかります。\nPrice\nSize\nTradeYear\nLargeDistrict\nTenure\n\n\n\n\n200\n105\n2022\n中心6区\n31\n\n\n150\n105\n2022\n中心6区\n33\n\n\n92\n105\n2022\n中心6区\n21\n\n\n110\n105\n2022\n中心6区\n30\nなぜこのような取引価格のブレが生じるのでしょうか？ データの誤入力など潜在的な理由は複数ありますが、有力なのはこのデータに含まれない重要な変数 が存在することです。 例えば、最寄駅や公園の近くにあるか否かなどのより詳細な立地情報が考えられます。 あるいは売り手や買い手の”交渉力”を反映している可能性もあります。 このような多様な要因が、取引価格に影響を与え、結果として事例の下振れ/上振れが生じます。\n観察できない変数は不動産のみならず、労働者や家計、企業、あるいは国レベルの分析でも同様の問題を引き起こします。 観察できる変数 \\(X\\) が一致した事例内でも、観察できない変数は事例間で大きく異なっている可能性が高く、結果 \\(Y\\) の値に大きな差が生まれます。 そして現実の社会や市場の複雑さを考慮すると、どれだけ詳細な調査（含むインタビュー調査や参与観察)を行ったとしても、\\(Y\\)に影響を与える全ての要因を観察することは困難です。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>要約の基本コンセプト</span>"
    ]
  },
  {
    "objectID": "model.html#観察できない変数が引き起こす問題",
    "href": "model.html#観察できない変数が引き起こす問題",
    "title": "1  要約の基本コンセプト",
    "section": "",
    "text": "1.1.1 コンセプト: 集計\n先の個別事例分析では、観察できない変数の偏りを確認する方法として、同じ\\(X\\)を持つ事例と比較しました。 このようなアプローチの発展として、同じ\\(X\\)を持つ事例集団について、\\(Y\\)の特徴を要約する方法があります。 例えば、平均値や分散、中央値、あるいは研究者による”所見”や”印象”、代表的な事例を紹介するなどです。\n恣意性の影響を緩和するために、調査計画を立てる時点で、要約方法も決定し、分析を通じてコミットすることが望まれます。 代表的な値の候補としては、中央値や最頻値など多くの候補があります。 現状よく用いられるのは、平均値の活用です。\n以下では、価格 (Price) と広さ (Size)、立地 (中心6区/その他)、取引年 (2021/2022)について、データに含まれる事例の分布をHeat mapで図示しています。\n\n\n\n\n\n\n\n\n\n上記の散布図は、社会分析に用いるデータの持つ典型的な特徴を表しています。 極めて乱雑であり、同じ\\(X\\) でも \\(Y\\) が異なる事例が多くなっています。 これは、観察できない変数の偏りが深刻である可能性を示唆しています。 また \\(X\\) の値に応じた事例数の偏りも顕著であり、特に100平米を超えるような物件の取引事例は少なくなっています。\n以下の各点は、各\\(X\\)の組み合わせごとに計算されたデータ上の平均値を図示しています。\n\n\n\n\n\n\nデータ上の平均値\n\n\n\n\\[\\frac{Y_1 + .. + Y_N}{N}\\]\nただし \\(Y_i\\) は第\\(i\\)事例の値、 \\(N\\) は事例数を表す。\n\n\n\n\n\n\n\n\nFigure 1.1: 平均値\n\n\n\n同図からは、\\(Y\\) と \\(X\\) のデータ上の関係性について、いくつか示唆を与えてます。 部屋が広くなると取引価格は高くなる傾向があり、この傾向は中心6区で特に顕著となります。\nしかしながら多くの応用では、このような\\(X\\)ごとに集計するだけでは、不十分です。 特に以下の問題に注意が必要です。\n\n\n1.1.2 集計の注意点\n\n1.1.2.1 少数事例の集計\n平均値は有力な要約方法ですが、算出に使用する事例の数に注意してください。 Figure 1.1 では、特に100平米を超える物件について少なくなっています。仮に平均値を計算するとしても、事例数が少ないと、各事例の観察できない変数の偏りの影響を強く受ける可能性があります。 この問題については、Chapter 2 で議論します。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>要約の基本コンセプト</span>"
    ]
  },
  {
    "objectID": "model.html#reference",
    "href": "model.html#reference",
    "title": "1  要約の基本コンセプト",
    "section": "1.2 Reference",
    "text": "1.2 Reference",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>要約の基本コンセプト</span>"
    ]
  },
  {
    "objectID": "population.html",
    "href": "population.html",
    "title": "2  母分布",
    "section": "",
    "text": "2.1 頻度論\n少数事例の集計が引き起こす問題を正確に理解するために、頻度論と呼ばれる枠組みを導入します1。 まず、「自分と同じ課題に取り組む他の研究者達」を想像してください。 この研究者達は、あなたと同じ社会を対象に同じ手法を用いて分析しています。 ただしデータは、独立して収集しているとします。 このような独立した研究者達は、あなたと同じ分析結果に到達するでしょうか？\n簡単な理科の実験であれば、実験の手続きが同じであれば、誰がやっても同い結論に到達します。 例えば水の沸騰温度については、水に不純物を入れないなどを守れば、誰がやっても100度で沸騰します。 このため誰がやっても同じ結果が導かれる”科学的事実”に合意することは容易です。\n対して現実社会における多くの現象については、独立した研究者は、同じ結論に到達することは困難です。 なぜならば、分析に用いる事例が異なるためです。 ほとんどの応用で、独立して収集したデータが、完全に一致する可能性は無視できるほど小さいでしょう。 このためある研究者が観察した事例を、別の研究者は確認できない可能性が高くなります。\n分析結果の不一致の典型例としては、報道機関による世論調査が挙げられます。 複数の調査結果が、毎月公開されていますが、その結果は各社で異なっています。 理由は複数考えられますが、最も単純なものは、調査対象となる回答者が異なるためです。 典型的な世論調査では、各社が独立して電話番号をランダムに発生させるなどの方法で、1000-2000名ほどの回答者を極力ランダムに選んでいます。 しかしながら、異なる調査に同じ人が回答する確率は、非常に低くなります。\n観察できない事例の存在は、データにおける観察できない変数の偏りをもたらします。 ある研究者には、偶然、公園に近い物件の取引事例ばかり集まってくるかもしれません。 このような研究者のデータで計算された取引価格の平均値は、他の研究者と比べて、上振れる可能性が高いです。 すなわち要約した値であったとしても、研究者間で同じ値に合意できなくなります。\n事例研究において、人々が同じ結果を観察できない、という問題は深刻です。 なぜならば、「独立した個人や組織が同じ結果を観察できるので推定結果を事実として認定する」、という強力な枠組みが活用できません。 この問題に対処するためには、何らかの概念的な枠組みが必要となります。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>母分布</span>"
    ]
  },
  {
    "objectID": "population.html#コンセプト-母分布とサンプリング",
    "href": "population.html#コンセプト-母分布とサンプリング",
    "title": "2  母分布",
    "section": "2.2 コンセプト: 母分布とサンプリング",
    "text": "2.2 コンセプト: 母分布とサンプリング\n観察できない事例の問題と、それに伴う分析結果の不一致の問題を適切に論じるために、母分布という分析概念を導入します。 母分布は、すべての研究者に共通した正答と各々のデータから得られる回答を、分離することを可能にします。\n「私たちが手にしているデータは、母集団という無数の事例の集団から、選ばれた事例から構成されている」と 想定 します。 さらに本ノートでは、事例は完全ランダムに選ばれていると仮定します。 このような仮定をランダムサンプリングと呼ばれます。\n私たちが得られる回答は、このランダムに選ばれた一部の事例のみから得たものであり、正答とは一致しません。\n例えば日本全体のすべての家計が母集団であり、母集団における夫婦間の平均的な家事分担を知りたいとします。 この場合、正答はすべての家計を調査し尽くせば得ることができます。 対して私たちのデータは、家計全体の一部であり、そこから得られる回答（データ上の平均的な家事分担）は、母集団における正答とは異なります。 日本全体では妻の方が夫よりも家事負担が大きかったとしても、データに含まれる事例が偶然偏り、回答としては夫の家事負担がより大きいという結果を得る可能性があります。\n母集団として、仮想的な集団を想定することもできます。 例えば、あるコンビニのレジデータに、ある日の全ての来客者について、購入金額が全て記録されているとします。 この場合、現実の来客者全てが記録されているため、母集団は存在しないと考えることも可能です。 一方で、その日にコンビニを訪れた顧客は、潜在的な顧客の一部であると想定することもできます。 皆さんも、よく利用するコンビニであったとしても、毎日利用しないのではないでしょうか？ この場合の母集団は、潜在的な顧客となります。\n母集団を想定すると、母集団における変数の分布も定義できます。 例えば、「取引物件の母集団において、中心6区に立地する物件の割合は2割」、といった感じです。 また母分布を定義できれば、そこから母集団における平均値(母平均)も定義できます。\n\n\n\n\n\n\n母平均\n\n\n\n\\(Y\\) の母集団における平均値\n\n\n平均値の推定を目指す研究であれば、この母平均が正答となります。 例えば、「中心6区に立地する50平米の中古マンションの2022年における平均取引価格は5000万円」、といった感じです。\n注意が必要なのは、「我々には母分布や母平均を正確に知ることは不可能である」ことがデータ分析法の前提である点です。 知ることができない母分布や母平均を、手元にある限られたデータから、以下に推測するのかが、データ分析の中心的な挑戦となります。 データが母集団の一部であり、観察できていない事例が存在する以上、データ上の平均値と母平均は一致しません。 またデータはランダムに選ばれているので、独立した研究者間で、平均値について厳密な合意はできません。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>母分布</span>"
    ]
  },
  {
    "objectID": "population.html#sec-Sim",
    "href": "population.html#sec-Sim",
    "title": "2  母分布",
    "section": "2.3 数値例",
    "text": "2.3 数値例\n以上の概念を明確にするために、簡単な数値実験を行います。 今、4名の研究者が独立して20事例を集めたとします。 各事例について、取引価格 \\(Y\\) と 部屋の広さ \\(X\\) がデータから観察できるとします\n母分布は以下のように設定しています。\n\n部屋の広さは、\\(X\\in\\{30,35,40,..,80\\}\\) が同じ割合で存在\n取引価格は、\n\n立地が中心6区ではなく部屋の広さが75以下であれば \\[50 + 0.1 \\times X + 0.001 \\times Size^2\\]\n立地が中心6区、または、部屋の広さが75以上であれば \\[55 + 0.1 \\times X + 0.001 \\times Size^2\\]\n立地が中心6区、かつ、部屋の広さが75以上であれば \\[60 + 0.1 \\times X + 0.001 \\times Size^2\\]\n\n\n以下の図は、4名の研究者が手にするデータと平均値を図示しています。\n\n\n\n\n\n\n\n\n\n平均値について、研究者間で大きな違いが見られます。\nこの図に母平均を上書きすると以下のようになります。 ただし図を簡略化するために、各事例の値は排除します。\n\n\n\n\n\n\n\n\n\n重要な点として、母平均とデータ上の平均は乖離していることを確認してください。 また乖離の仕方は、研究者によって異なります。 言い換えるならば、母平均は全員共通である一方で、データ上の平均値は異なっています。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>母分布</span>"
    ]
  },
  {
    "objectID": "population.html#大数の法則",
    "href": "population.html#大数の法則",
    "title": "2  母分布",
    "section": "2.4 大数の法則",
    "text": "2.4 大数の法則\n母平均を知る”唯一”の方法は、各\\(X\\)の組み合わせについて、無限大の事例数で平均値を計算することです。 これは大数の法則が成立するためです。\n\n\n\n\n\n\n大数の法則\n\n\n\n無限大の事例数をもつランダムサンプリングデータにおいて、計算された\\(Y\\)の平均値は、母平均と一致する。\n\n\n以下では、事例数を20,200,2000,20000に随時変更した数値例を示しています。\n\n\n\n\n\n\n\n\n\n20事例では、母平均とデータ上の平均値が大きく乖離してますが、20000事例ではほぼ一致していることが確認できます。\n大数の法則は重要な理論的性質ですが、実践上の含意は限られています。 多くの応用において、大量の\\(X\\)の組み合わせが発生します。 このため十分な事例数を確保することは、事実上不可能なためです。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>母分布</span>"
    ]
  },
  {
    "objectID": "population.html#reference",
    "href": "population.html#reference",
    "title": "2  母分布",
    "section": "2.5 Reference",
    "text": "2.5 Reference\n\n\n\n\nLin, Hanti. 2024. “To Be a Frequentist or Bayesian? Five Positions in a Spectrum.” Harvard Data Science Review 6 (3).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>母分布</span>"
    ]
  },
  {
    "objectID": "population.html#footnotes",
    "href": "population.html#footnotes",
    "title": "2  母分布",
    "section": "",
    "text": "頻度論以外にはベイズ法と呼ばれる枠組みもあります。Lin (2024)などを参照ください。↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>母分布</span>"
    ]
  },
  {
    "objectID": "OLS.html",
    "href": "OLS.html",
    "title": "3  データ上でのOLS",
    "section": "",
    "text": "3.1 線型モデル\n\\(Y\\) の平均値と \\(X\\) の関係性を記述するモデルを導入します。\n以下では\\(\\beta_0,..,\\beta_L\\)を決定する具体的な方法として、OLSを紹介します。\n線型モデルをどのように解釈すれば良いでしょうか？ 最も実践的な解釈は、平均値の”補助線”として捉えることです。\n以下の図では、Priceの平均値とSizeの関係性を捉えるための3つの”補助線”を描きこんいます。 すべて \\(\\beta_0 + \\beta_1\\times Size\\) を使用し、パラメタの値のみ変更しています。\nデータ上の平均値は紫の点で示しています。 赤線は \\(0.05 + 0.7\\times Size\\)、 緑線は \\(30 + 0.5\\times Size\\)を示しています。\n水色線は \\(80\\) 、すなわち\\(\\beta_0=80,\\beta_1=0\\) とした補助線を示しています。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>データ上でのOLS</span>"
    ]
  },
  {
    "objectID": "OLS.html#ols",
    "href": "OLS.html#ols",
    "title": "3  データ上でのOLS",
    "section": "3.2 OLS",
    "text": "3.2 OLS\nパラメタの値は、データに基づいて決定されることが通常です。 代表的な決定方法としては、最小二乗法 (OLS) が挙げられます。\n\n\n\n\n\n\nOLSの定義\n\n\n\n\n研究者が予測モデルの大枠を以下のように設定する \\[予測モデル=\\beta_0 + \\beta_1X_1 + \\beta_2X_2 +.. + \\beta_LX_L\\]\n以下を最小化するように \\(\\beta_0,..,\\beta_L\\) を決定する \\[(Yの平均値-予測モデル)^2のデータ上の平均\\]\n\n\n\nOLSは、研究者が事前に大枠を設定した予測モデルを、データに最も合うように推定する手法であると解釈できます。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>データ上でのOLS</span>"
    ]
  },
  {
    "objectID": "OLS.html#数値例-事例数の拡大",
    "href": "OLS.html#数値例-事例数の拡大",
    "title": "3  データ上でのOLS",
    "section": "3.4 数値例: 事例数の拡大",
    "text": "3.4 数値例: 事例数の拡大\n推定結果は、一般に事例数に強く影響を受けます。 特にLASSOなどの機械学習の方法においては、データの特徴により強く依存します。\n以下の数値例では、事例数を20,200,2000,20000まで増やしています。\n単純平均値の推定結果は以下です。\n\n\n\n\n\n\n\n\n\n事例数が増加したとしても、推定結果があまり変化していないのを確認できます。 これは少数事例であったとしても、大規模事例と同じ推定結果を獲得しやすいことを意味している一方で、20000事例まで増やしても母平均に十分に近づいていません。\n\\(Y\\sim Size\\) をOLSで推定した結果は以下です。\n\n\n\n\n\n\n\n\n\n小規模事例 (20事例)では、推定結果が大きく変化し、母平均から大きく乖離していることが確認できます。\n\\(Y\\sim Size +..+ Size^6\\) をOLSで推定した結果は以下です。\n\n\n\n\n\n\n\n\n\n事例数の影響を強く受けています。 小規模事例 (20事例)では、過剰に複雑なモデルが推定されており、母平均から大きく乖離しています。 事例数が増加するにつれて、推定結果が母平均とほぼ一致しています。\n大規模事例のもとでは、母平均を近似できる一方で、小規模事例では推定結果が不安定になることが確認できます。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>データ上でのOLS</span>"
    ]
  },
  {
    "objectID": "OLS.html#rによる実践例",
    "href": "OLS.html#rによる実践例",
    "title": "3  データ上でのOLS",
    "section": "3.5 Rによる実践例",
    "text": "3.5 Rによる実践例\n\n以下のパッケージを使用\n\nreadr (tidyverseに同梱): データの読み込み\n\n\n\n3.5.1 準備\nデータとその事例数を取得し、データをランダムに分割します。\n\nData = readr::read_csv(\"Public.csv\") # データ読み込み\n\nN = nrow(Data) # 事例数の取得\n\nGroup = sample(\n  1:2,\n  N, # 事例数\n  replace = TRUE, # 復元抽出を指定\n  prob = c(0.8,0.2) # \"1\"が8割、\"2\"が２割\n) # サンプル分割のために1または2をランダムに発生\n\nTrain = Data[Group == 1,] # 訓練データ\nTest = Data[Group == 2,] # テストデータ\n\nlm関数を用いてOLS, hdmパッケージ内のrlasso関数を用いてLASSO推定をします。 またLASSO推定は、複雑なモデルを推定に利点を持つため、交差項と二乗項までを導入したモデルも推定しています。\n\nOLS = lm(Price ~ Size + Tenure + District + StationDistance,\n         Train) # OLS\n\nテストデータを用いて推定された平均二乗誤差は以下です。\n\nmean((Test$Price - predict(OLS,Test))^2)\n\n[1] 241.6931\n\n\n二乗項と交差項を含めたモデルをLASSOで推定した予測モデルが、予測性能が最も高くなりました。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>データ上でのOLS</span>"
    ]
  },
  {
    "objectID": "OLS.html#reference",
    "href": "OLS.html#reference",
    "title": "3  データ上でのOLS",
    "section": "3.6 Reference",
    "text": "3.6 Reference",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>データ上でのOLS</span>"
    ]
  },
  {
    "objectID": "OLS.html#footnotes",
    "href": "OLS.html#footnotes",
    "title": "3  データ上でのOLS",
    "section": "",
    "text": "異なるのアプローチは、Spiess, Venugopal, et al. (2024) などを参照↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>データ上でのOLS</span>"
    ]
  },
  {
    "objectID": "LASSO.html",
    "href": "LASSO.html",
    "title": "4  LASSO",
    "section": "",
    "text": "4.0.0.1 事例数の拡大\n推定結果は、一般に事例数に強く影響を受けます。 特にLASSOなどの機械学習の方法においては、データの特徴により強く依存します。\n以下の数値例では、事例数を200事例から50000事例まで増やし、 \\(Y\\sim Size + District\\) をOLSで、\\(Y\\sim (Size + Size^2 + .. + Size^6) * District\\) をLASSOで推定しています。\n上記結果は、事例数が拡大すると、サンプル平均と母平均の乖離が減少していることが確認できます。 さらにLASSOとサンプル平均との乖離も減少しており、結果、LASSOが母平均を上手く近似できていることが確認できます。 対して単純なモデルのOLS推定は、分析者が設定したモデルに推定結果が大きく制約されており、事例数増加の恩恵が十分に得られません。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>LASSO</span>"
    ]
  },
  {
    "objectID": "LASSO.html#rによる実践例",
    "href": "LASSO.html#rによる実践例",
    "title": "4  LASSO",
    "section": "4.1 Rによる実践例",
    "text": "4.1 Rによる実践例\n\n以下のパッケージを使用\n\nreadr (tidyverseに同梱): データの読み込み\nhdm: LASSO\n\n\n\n4.1.1 準備\nデータとその事例数を取得し、データをランダムに分割します。\n\nData = readr::read_csv(\"Public.csv\") # データ読み込み\n\nN = nrow(Data) # 事例数の取得\n\nGroup = sample(\n  1:2,\n  N, # 事例数\n  replace = TRUE, # 復元抽出を指定\n  prob = c(0.8,0.2) # \"1\"が8割、\"2\"が２割\n) # サンプル分割のために1または2をランダムに発生\n\nTrain = Data[Group == 1,] # 訓練データ\nTest = Data[Group == 2,] # テストデータ\n\nlm関数を用いてOLS, hdmパッケージ内のrlasso関数を用いてLASSO推定をします。 またLASSO推定は、複雑なモデルを推定に利点を持つため、交差項と二乗項までを導入したモデルも推定しています。\n\nLASSO = hdm::rlasso(Price ~ Size + Tenure + District + StationDistance,\n                    Train) # LASSO\n\nLASSO_Long = hdm::rlasso(\n  Price ~ (Size + Tenure + District + StationDistance)**2 +\n    poly(Size,2) + poly(Tenure,2) + poly(StationDistance,2),\n  Train) # LASSO (含む二乗項と交差項)\n\nLASSOで推定されたモデルで使用される変数リストは、以下で表示できます。 Trueが選択された変数です。\n\nLASSO$index\n\n            Size           Tenure   District中央区   District中野区 \n            TRUE             TRUE             TRUE             TRUE \n    District北区 District千代田区   District台東区   District品川区 \n            TRUE             TRUE            FALSE            FALSE \n  District大田区   District文京区   District新宿区   District杉並区 \n            TRUE            FALSE             TRUE            FALSE \n  District板橋区 District江戸川区   District江東区   District渋谷区 \n            TRUE             TRUE             TRUE             TRUE \n    District港区   District目黒区   District練馬区   District荒川区 \n            TRUE             TRUE             TRUE             TRUE \n  District葛飾区   District豊島区   District足立区   District墨田区 \n            TRUE            FALSE             TRUE             TRUE \n StationDistance \n            TRUE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>LASSO</span>"
    ]
  },
  {
    "objectID": "LASSO.html#reference",
    "href": "LASSO.html#reference",
    "title": "4  LASSO",
    "section": "4.2 Reference",
    "text": "4.2 Reference\n\n\n\n\nTibshirani, Robert. 1996. “Regression Shrinkage and Selection via the Lasso.” Journal of the Royal Statistical Society Series B: Statistical Methodology 58 (1): 267–88.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>LASSO</span>"
    ]
  },
  {
    "objectID": "prediction.html",
    "href": "prediction.html",
    "title": "5  応用: 予測",
    "section": "",
    "text": "5.1 推定目標\n本ノートでは、データと同じ母集団から新たに抽出された事例を、予測するモデルの推定を目指します。 予測能力は、平均事情誤差で測定します \\[母集団における平均二乗誤差 = (Y - 予測値)^2 の母集団における平均\\] 注意が必要なのは、母集団における平均二乗誤差は、母集団上の値であり、直接観察することは不可能です。 ただし本章で紹介する通り、推定することは可能です。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>応用: 予測</span>"
    ]
  },
  {
    "objectID": "prediction.html#推定目標",
    "href": "prediction.html#推定目標",
    "title": "5  応用: 予測",
    "section": "",
    "text": "5.1.1 完璧な予測モデル\n予測研究における究極的な目標の一つは、 \\(Y\\) を完璧に予測するモデルの推定です。 しかしながら多くの応用で、この目標には到達することができません。 予測モデルは、ある\\(X\\)の組み合わせについて、一つの予測値のみを出力します。 このため母集団において、同じ\\(X\\) 内で\\(Y\\) の値にばらつきがあれば、予測が外れる事例は必ず存在します。\n完璧な予測には、\\(Y\\)の全ての決定要因を\\(X\\)として観察し、\\(X\\)内での個人差をなくす必要があります。 しかしながら人間行動や社会的な事象などの社会的変数の決定要因は無数に存在し、その多くは観察が難しいと考えられます。 結果、社会的変数について、完璧な予測は不可能と考えられます。\n\n\n5.1.2 理想の予測モデル\n最も高い予測性能 (母集団における平均二乗誤差が最小化)を達成する予測モデルは、母平均であることが証明できます \\[理想の予測モデル = X内でのYの母平均\\]\n予測研究においては、データから推定した予測モデルを理想の予想モデルである母平均に極力近づけることが、実質的な目標となります。 具体的には以下の予測誤差を極力削減することを目指します \\[(\\underbrace{X内でのYの母平均}_{理想の予測モデル}-予測モデル)^2の母平均\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>応用: 予測</span>"
    ]
  },
  {
    "objectID": "prediction.html#reference",
    "href": "prediction.html#reference",
    "title": "5  応用: 予測",
    "section": "5.2 Reference",
    "text": "5.2 Reference",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>応用: 予測</span>"
    ]
  },
  {
    "objectID": "evaluation.html",
    "href": "evaluation.html",
    "title": "6  応用: 予測性能の評価",
    "section": "",
    "text": "6.1 予測性能の測定\n予測を目指す分析では、推定された予測モデルの性能を評価することが重要となります。 現状、幅広いデータや状況において、一貫して高い予測性能を生み出す方法は存在しません。 このため複数の予測モデルを”試作”し、その性能を比較することが分析工程に組み込まれています。\n最もシンプルな評価方法は、サンプル分割です。\n実際の取引データに適用した結果は以下です。 6378事例のうち、ランダムに選んだ半分を訓練、残り半分をテストに用いました。 テストした推定方法は以下です。\n推定された予測モデルの評価結果は以下となりました。\nOLS\nOLS| 交差項 + 高次項\nLASSO\n\n\n\n\n369\n316\n303\nLASSOが最も予測性能が高く、単純なOLSと比較し、0.179 パーセントほど平均二乗誤差を削減しています。 対して、交差項と高次項を追加したOLSとLASSOを比較した場合、0.041 パーセントほどの改善にとどまります。 これはモデルの複雑さに比べて、事例数が多く、LASSOによるモデル単純化の恩恵が限定的であることを示しています。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>応用: 予測性能の評価</span>"
    ]
  },
  {
    "objectID": "evaluation.html#予測性能の測定",
    "href": "evaluation.html#予測性能の測定",
    "title": "6  応用: 予測性能の評価",
    "section": "",
    "text": "サンプル分割法の定義\n\n\n\n\nデータをランダムに訓練データとテストデータに分割する\n\n\n訓練/テスト間での事例数の比率については、8対2や95対5が(経験則として)推奨されることが多い。\n\n\n訓練データのみでモデルを試作する\nテストデータへの当てはまりを(平均二乗誤差などで)評価する\n\n\n\n\n\nOLS: 取引価格 ~ 部屋の広さ + 立地 + 取引年\nOLS (含む交差項 + 高次項): 取引価格 ~ 部屋の広さ + 立地 + 取引年 + 交差項 + 高次項(６次まで)\nLASSO (含む交差項 + 高次項): 取引価格 ~ 部屋の広さ + 立地 + 取引年 + 交差項 + 高次項(６次まで)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>応用: 予測性能の評価</span>"
    ]
  },
  {
    "objectID": "evaluation.html#まとめ",
    "href": "evaluation.html#まとめ",
    "title": "6  応用: 予測性能の評価",
    "section": "6.2 まとめ",
    "text": "6.2 まとめ\n\n予測誤差の他の測定方法については、Angelopoulos, Bates, et al. (2023) などを参照",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>応用: 予測性能の評価</span>"
    ]
  },
  {
    "objectID": "evaluation.html#reference",
    "href": "evaluation.html#reference",
    "title": "6  応用: 予測性能の評価",
    "section": "6.3 Reference",
    "text": "6.3 Reference\n\n\n\n\nAngelopoulos, Anastasios N, Stephen Bates, et al. 2023. “Conformal Prediction: A Gentle Introduction.” Foundations and Trends in Machine Learning 16 (4): 494–591.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>応用: 予測性能の評価</span>"
    ]
  },
  {
    "objectID": "OLS.html#線型モデル",
    "href": "OLS.html#線型モデル",
    "title": "3  データ上でのOLS",
    "section": "",
    "text": "線型モデル\n\n\n\n\\[Yの平均値\\simeq\\beta_0 + \\beta_1X_1 + \\beta_2X_2 +.. + \\beta_LX_L\\]\n\n\\(\\beta_0,..,\\beta_L\\) はパラメタと呼ぶ",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>データ上でのOLS</span>"
    ]
  },
  {
    "objectID": "OLS.html#単純平均法",
    "href": "OLS.html#単純平均法",
    "title": "3  データ上でのOLS",
    "section": "3.2 単純平均法",
    "text": "3.2 単純平均法\n少数事例の要約を避けるためには、より”荒い”要約が必要となります。 最も極端な方法は、\\(Y\\) のデータ全体での単純平均を予測値とする方法です。\n数値例は以下です。\n\n\n\n\n\n\n\n\n\n単純平均法では、予測値は\\(X\\)の値に依存せずに一定です。 このため丸暗記法に比べて、予測モデルが単純化されてると言えます。 ただし\\(X\\) と \\(Y\\) の母平均との間での関係性を一切無視した集計になっており、依然として母平均との乖離が生じています。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>データ上でのOLS</span>"
    ]
  },
  {
    "objectID": "OLS.html#例",
    "href": "OLS.html#例",
    "title": "3  データ上でのOLS",
    "section": "3.3 例",
    "text": "3.3 例\n\n\n\n\n\n\n\n\n\n最もシンプルな線型モデルとして、例えば以下を推定してみます。 \\[予測値 = \\beta_0 + \\beta_1\\times Size\\] \\(\\beta_0,\\beta_1\\) は、以下のデータ上の平均二乗誤差を最小化するように推定します。\\[(Y - 予測値)^2 のデータ上の平均\\] このような推定方法は、単回帰として教科書では紹介されてきました。\n推定結果を図示すると、以下となります。\n\n\n\n\n\n\n\n\n\n単純平均とは異なり、広い物件は取引価格が高くなる傾向を捉えることができています。 さらに丸暗記法ほど、母平均から大きく乖離した予測も見られません。 これは丸暗記法と比べて、事例の要約が機能していることを表しています。\nしかしながら母平均に比べると、以前として単純すぎます。 特に立地に応じて、平均価格が異なるという性質を捉えきれていません。\n\n3.3.0.1 重回帰\nDistrictと平均取引価格の関係性を捉えるために、以下のモデルの推定を試みます。 \\[予測値 = \\beta_0 + \\beta_1\\times Size + \\beta_2\\times District\\] \\(District\\) は、中心６区に立地していれば1、それ以外では0を取ります。 \\(\\beta_0,..,\\beta_2\\) は引き続き、データへの適合度を最大化するように推定できます。 このような推定方法は、重回帰として教科書では紹介されてきました。\n推定結果を図示すると、以下となります。\n\n\n\n\n\n\n\n\n\n中心6区の方が平均取引価格が高いという性質を上手く捉えています。 しかしながら、Sizeが70平米を超えると、取引価格が一段上昇するという性質は捉えきれていません。\n\n\n3.3.0.2 交差項と高次項の導入\n母平均が持つ複雑な性質を捉えるために、交差効果と高次項を導入し、さらに複雑なモデルを推定してみます。 \\[予測値 = \\beta_0 + \\beta_1 Size+\\beta_7District + \\underbrace{\\beta_2Size^2 +..+\\beta_6Size^6}_{高次項}\\] \\[+\\underbrace{\\beta_8 Size\\times District +..+\\beta_{14}Size^6\\times District}_{交差効果}\\] このような複雑なモデルであったとしても、データへの適合度を最大化するように推定できます。\n\n\n\n\n\n\n\n\n\n複雑なモデルを最小二乗法で推定すると、よりデータへの適合度を改善し、データ上の平均値に近づけることができます。 しかしながらここまで議論してきた通り、このことは必ずしも望ましいとはいえません。 なぜならば、丸暗記法により推定されたモデルに近づくからです。 少数の事例しかない\\(X\\)の組み合わせについては、丸暗記法と同様に母平均から乖離し、予測性能が悪化します。\n線型モデルを複雑にしすぎると丸暗記モデルになり、単純化しすぎると単純平均モデルとなります。 この中間的なモデルが予測性能が高いことが多いですが、分析者がそのようなモデルを適切に設定することは困難です。 機械学習では、この問題に対して、データに基づく解決策を提案しています。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>データ上でのOLS</span>"
    ]
  }
]