[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "データ分析入門ノート",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#本ノートの狙い",
    "href": "index.html#本ノートの狙い",
    "title": "データ分析入門ノート",
    "section": "本ノートの狙い",
    "text": "本ノートの狙い\n初学者に対して、データ分析法、具体的な分析工程に埋め込みながら紹介します。 分析法の急速な多様化に対応するため、分析のゴールに応じた整理し、実践への活用における混乱を減らすことに重点を置きます。 具体的には、以下の点に注意して、本ノートは作成されています。\n\n２種類の分析のゴール、「新しい事例について欠損情報の予測を行う予測」と 「事例全体についてその特徴を把握するための分析法」、を紹介します。 把握のための分析の具体例としては、比較分析を主に扱います。例えば男女間賃金格差や前年と比較した場合の不動産価格変化など、集団間で見られる違いを把握する方法を紹介します。さらに格差の分解分析や因果推論などを目的とする研究で重要なバランス後の比較分析(Balanced Comparison)も紹介します。\n平均値の推定やOLSといった計量経済学の入門書で紹介される伝統的な手法だけでなく、LASSOなどといった教師付き学習(機械学習の一分野)の手法も議論します。 分析のゴールが予測であるならば機械学習に比較優位があり、集団の特徴を把握であるならば、伝統的な手法に比較優位があることを、その理由とともに強調します。 さらに発展的な比較をゴールとする場合、教師付き学習と伝統的な手法のハイブリット的な手法が有効であることも論じます。\n予測と把握という分析のゴールの使い分け方を、具体的な意思決定を想定しながら整理します。 データ分析の目的を、意思決定に役立つ情報提供にあると位置付け、意思決定の種類に応じた分析のゴールを論じます。特に限られた事例にのみ影響を与える意思決定 (ミクロな意思決定)と大量の事例に影響を与える意思決定 (マクロな意思決定)を区別します。 教師付き学習がもたらす事例ごとの予測は、ミクロな意思決定においては非常に有効であったとしても、マクロな意思決定においてはそのままでは活用が難しいことを強調します。これは大量の事例について提供される大量の予測値を、意思決定者が活用することが難しいためです。 マクロな意思決定においては、大量の事例群の特徴を把握が必要になり、このためには伝統的な手法が比較優位を持ちます。 ただし複雑な特徴を把握する上では、伝統的な手法と教師付き学習のハイブリット的な手法が有効になることを強調します。",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#ノートの背景",
    "href": "index.html#ノートの背景",
    "title": "データ分析入門ノート",
    "section": "ノートの背景",
    "text": "ノートの背景\n本ノート作成の背景には、データ分析法の多様化とそれに伴う混乱があります。 データを用いた社会分析は、長い伝統を持ちます。 例えば経済学においては、古くからデータ分析が活用され、計量経済学と呼ばれる方法論開発を行う研究分野には多くの研究者が参入し、活発な議論が行われてきました。 また実際のデータを用いた実証研究も数多く行われ、伝統的にはOLSなどのモーメント法や最尤法などが用いられてきました。 さらに機械学習と親和性の高いNonparametric推定やハイブリット的な手法の基礎となる議論 (Semi-parametric推定)も発展してきました。 しかしながらこのような発展的な議論は、入門書ではあまり紹介されてきませんでした。\n近年、コンピュータの計算能力増大などを背景に、伝統的な分析手法のみならず、機械学習と総称される分析手法の活用が急速に進んでいます。 特に教師付き学習と呼ばれる分野は、経済学における伝統的な推定手法と近い手法や問題意識を有しつつ、データの柔軟な活用方法を提供しています。 実際に、教師付き学習の教科書では、ほぼ例外なくLogitやOLSは紹介され、母分布を用いた論点整理がなされていますが、同時に、計量経済学の入門書ではあまり紹介されてこなかった、Data adaptive modellingの手法が数多く提案されています。 伝統的な推定手法の多くが、「人間によってシンプルな 推定モデルの設定を行い、その限られたパラメタをデータにより推定する」という手続きを踏むのに対して、決定木やLASSOは、「大量のパラメタを、データによる適切に推定する」ことを可能にします。\nこのような分析方法の多様化は、同時に応用研究における混乱ももたらしえます。例えば Breiman (2001) は、「機械学習は、伝統的な統計学の \\(95 \\%\\) と異なる”文化”を持っている」と主張し、多くの議論 (Shmueli 2010; Efron 2020; Hofman et al. 2021) を想起しました。 このような議論の中で、手法を有効活用するために、分析のゴールをしっかり意識することの重要性が指摘され、ゴールによっては伝統的な手法と機械学習のハイブリット的な方法の有効性が指摘されています(Van der Laan and Rose 2011; Chernozhukov et al. 2018, 2022)。\nこれらの研究の成果は、上級レベルの計量経済学のテキストでは紹介され、またChernozhukov et al. (2024)や Wager (2024), 末石直也 (2024) などで集中的にまとめられています。 しかしながら、現状入門的な日本語の教材は見当たりません。 本ノートは、この空白を埋めることを目的としています。",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#章立て",
    "href": "index.html#章立て",
    "title": "データ分析入門ノート",
    "section": "章立て",
    "text": "章立て\n\nSection 1  分析例\nSection 2  要約の基本コンセプト\nSection 3  予測を目的とする要約\nSection 4  把握を目的とする要約: 単純な比較\nSection 5  把握を目的とする要約: Balanced Comparison\nSection 6  Balancing Weightの推定: 特徴のバランス\nSection 7  Balancing Weightの推定: 傾向スコア\nSection 8  Balanced Comparisonの改善: Augmentation",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#reference",
    "href": "index.html#reference",
    "title": "データ分析入門ノート",
    "section": "Reference",
    "text": "Reference\n\n\n\n\nBreiman, Leo. 2001. “Statistical Modeling: The Two Cultures.” Statistical Science 16 (3): 199–231.\n\n\nChernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. “Double/debiased machine learning for treatment and structural parameters.” The Econometrics Journal 21 (1): C1–68. https://doi.org/10.1111/ectj.12097.\n\n\nChernozhukov, Victor, Juan Carlos Escanciano, Hidehiko Ichimura, Whitney K Newey, and James M Robins. 2022. “Locally Robust Semiparametric Estimation.” Econometrica 90 (4): 1501–35.\n\n\nChernozhukov, Victor, Christian Hansen, Nathan Kallus, Martin Spindler, and Vasilis Syrgkanis. 2024. “Applied Causal Inference Powered by ML and AI.” arXiv Preprint arXiv:2403.02467.\n\n\nEfron, Bradley. 2020. “Prediction, Estimation, and Attribution.” International Statistical Review 88: S28–59.\n\n\nHofman, Jake M, Duncan J Watts, Susan Athey, Filiz Garip, Thomas L Griffiths, Jon Kleinberg, Helen Margetts, et al. 2021. “Integrating Explanation and Prediction in Computational Social Science.” Nature 595 (7866): 181–88.\n\n\nShmueli, Galit. 2010. “To Explain or to Predict?” Statistical Science 25 (3): 289–310.\n\n\nVan der Laan, Mark J, and Sherri Rose. 2011. Targeted Learning. Vol. 1. 3. Springer.\n\n\nWager, Stefan. 2024. “Causal Inference: A Statistical Learning Approach.” preparation.\n\n\n末石直也. 2024. データ駆動型回帰分析: 計量経済学と機械学習の融合. 日本評論社.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "stracture.html",
    "href": "stracture.html",
    "title": "1  分析例",
    "section": "",
    "text": "1.1 データ\n本ノートにおいてデータ分析法は、「事例から学ぶ方法」として位置付けます。 事例とは、過去の経験や出来事、歴史などであり、その蓄積をデータと呼びます。 例えば以下は、2021年と2022年の第二四半期の東京23区における中古マンション取引事例1をデータ化しています。\nPrice\nSize\nTenure\nStationDistance\nDistrict\n\n\n\n\n4.41\n70\n9\n4\n台東区\n\n\n3.53\n25\n11\n3\n世田谷区\n\n\n2.64\n30\n37\n13\n江戸川区\n\n\n4.09\n55\n30\n7\n中央区\n\n\n3.09\n25\n22\n4\n中央区\n\n\n4.87\n65\n16\n4\n港区\n\n\n3.56\n35\n10\n4\n台東区\n\n\n2.30\n20\n35\n4\n新宿区\n\n\n4.08\n65\n17\n7\n台東区\n\n\n3.00\n15\n24\n8\n新宿区\n以上のような取引事例が 24645 個収録されています。 このようなデータを用いて、以下のような意思決定問題に役立つ情報提供のあり方を、ラフに論じます。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>分析例</span>"
    ]
  },
  {
    "objectID": "stracture.html#分析工程",
    "href": "stracture.html#分析工程",
    "title": "1  分析例",
    "section": "1.2 分析工程",
    "text": "1.2 分析工程\n以上のようなデータを活用するためには、まず分析工程を設定することが重要です。 本ノートが、想定する分析工程の大枠は以下です。\n\n\n\n\n\n\n\n\n\n\nQ\n直面する意思決定問題\n\n\n\nUnderstand\n分析目標: 事例全体の特徴把握\n\n\n\nQ-&gt;Understand\n\n\n\n\n\nPrediction\n分析目標: 事例ごとの予測\n\n\n\nQ-&gt;Prediction\n\n\n\n\n\nEstimand\n比較\n\n\n\nUnderstand-&gt;Estimand\n\n\n\n\n\nDML\nバランス後の比較\n\n\n\nUnderstand-&gt;DML\n\n\n\n\n\nPredModel\n予測モデル\n\n\n\nPrediction-&gt;PredModel\n\n\n\n\n\nDML-&gt;PredModel\n\n\n\n\n\n\n\n\n\n\n\n1.2.1 意思決定問題の設定\nデータ分析を始めるための最初のステップは、分析結果をどのような意思決定問題に活用するのか、明確なイメージを持つことです2。 活用方法に応じて、適した分析のゴール、ひいては分析方法も異なってきます。\nAgrawal, Gans, and Goldfarb (2018) は意思決定問題を、「予測と判断(Judgement)」に分解しています。 そして機械学習は予測の改善に役を立ち、人間により行われる判断を補完すると主張してます。 本ノートでは、機械学習や統計学、計量経済学の手法は、狭義の予測のみならず、広義の現状把握に役立つを強調します。 一般に意思決定において、社会や市場の状況について、包括的な状況把握が必要となります。 そして社会や市場の全てのを直接観察することはできず、過去の経験や事例から類推するしかありません。\n上記データと関連する例として、中古マンション販売業者による中古マンションの査定金額算出や、支店網や営業戦略の再編(どの地域に注力すべきか)に有益な分析結果を提供できる可能性があります。\n次にその意思決定問題に有益な情報を明確にすることで、分析のゴールを設定します。 ここでは大きく予測を目的とする研究と集団の特徴把握を目標とする研究に大別し論じます。 次にそれぞれのゴールに適した手法を用いた推定を行い、分析結果を得ます。 ここでは予測を目標とする研究であれば教師付き学習の手法、把握を目標とするのであれば伝統的な手法、より複雑な特徴を把握したいのであればそのハイブリット的な方法に比較優位があることを論じます。\n\n\n1.2.2 分析目標\n応用を想定する意思決定問題と活用できるデータに応じて、分析目標を適切に設定する必要があります。 ここで本ノートでは、分析目標は大きく、「各事例に応じた予測」、または「事例全体の特徴把握」に大別することに注意してください。 この分類は、機械学習や傾向スコア、Balancing weightsなど、年々多様化する分析手法を整理する前提となります。 以下、これらの分析目標と結果、および意思決定問題の例を、具体的な分析例とともに紹介します。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>分析例</span>"
    ]
  },
  {
    "objectID": "stracture.html#分析例-取引価格予測",
    "href": "stracture.html#分析例-取引価格予測",
    "title": "1  分析例",
    "section": "1.3 分析例: 取引価格予測",
    "text": "1.3 分析例: 取引価格予測\n土地や中古マンション等の取引においては、これら資産の市場価格の算出が重要な役割を持ちます。 しかしながら不動産は、他の商品や資産と比べても、多くの属性（広さや立地、築年数等）をもち、市場価格の算出は困難です。\nChapter 3 で紹介する手法は、中古マンションの属性から、市場での取引価格を予測するモデル(予測モデル)の推定を目指しています。 このようなデータ主導の予測は、実際の不動産価値の鑑定に応用されています3。\n具体例として、以下の8事例について、中古マンションの取引価格を予測します。\n\n\n\n\n\n\n\n\nSize\nStationDistance\nTenure\nDistrict\n\n\n\n\n35\n8\n8\n品川区\n\n\n95\n8\n16\n豊島区\n\n\n25\n8\n7\n北区\n\n\n60\n8\n23\n台東区\n\n\n50\n2\n18\n中央区\n\n\n75\n10\n16\n江東区\n\n\n\n\n\n\n\n東京２３区内の中古マンションの取引データから、\\(X=\\{\\)取引された物件の築年数 (Tenure)、 部屋の広さ (Size)、駅からの距離 (Distance to Station)、立地 (District) \\(\\}\\) から予測するモデルを推定し、予測値を実際に算出してみました。 予測モデルは、LASSO/OLS/RandomForestのStacking法で推定しています。\n\n\n\n\n\n\n\n\nPrediction\nSize\nStationDistance\nTenure\nDistrict\n\n\n\n\n81.78570\n70\n4\n9\n台東区\n\n\n29.12521\n25\n3\n11\n世田谷区\n\n\n13.77940\n30\n13\n37\n江戸川区\n\n\n54.77992\n55\n7\n30\n中央区\n\n\n26.25486\n25\n4\n22\n中央区\n\n\n107.00030\n65\n4\n16\n港区\n\n\n36.45620\n35\n4\n10\n台東区\n\n\n15.34824\n20\n4\n35\n新宿区\n\n\n\n\n\n\n\n港区、築10年、65平米、駅から４分の物件が、最も高い取引価格(1億700万円)が予測されました。 対して、江戸川区、築37年、30平米、駅から13分の物件については、予測取引価格は1378万円であり、大きな格差が予測されました。\n以上のような分析の前提は、予測対象 (中古マンション) について、大量の事例が利用できることです。 もしこのようなデータが活用できるのであれば、事例ごとにきめ細かい予測を提供することができます。 機械学習の活用すれば、多くの属性を用いた複雑な予測モデルも容易に推定できます(Chapter 3)。\n以上ような前提が満たされやすい意思決定問題は、決定が影響を与える範囲が狭いミクロな意思決定であることが多いと考えらます。 例えば不動産取引の直接的な影響は、当該取引に関わる売手と買い手に限定されます。 このため目の前の物件についての予測が重要であり、このような物件についての取引事例については膨大な蓄積があります。\n対して幅広い層が影響を受けるマクロな意思決定においては、事例ごとの予測の活用は困難です。 不動産会社が、どのような地域に経営資源を投入するのか、を決定する差には、地域の不動産市場の動向把握が重要であると考えられます。 この場合、各地域には膨大な数の物件が存在しており、仮に事例ごとに詳細な予測値が提供できたとしても、大量の予測値を人間が定式に認識し活用することは極めて困難です。 このような場合、事例の集計値を推定し、活用することが必要となります。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>分析例</span>"
    ]
  },
  {
    "objectID": "stracture.html#分析例-取引価格の比較",
    "href": "stracture.html#分析例-取引価格の比較",
    "title": "1  分析例",
    "section": "1.4 分析例: 取引価格の比較",
    "text": "1.4 分析例: 取引価格の比較\n2022年と2021年の東京23区内の中古マンション市場を比較しました。\n\n2022-2021年比較: \\(\\{\\) Tenure, Size, Distance to Station \\(\\}\\)の差を95\\(\\%\\) 信頼区間 (Bonferoni法による修正済み)を表示\nバランス前-後平均取引価格上昇率: 取引価格の対数値について、2022年と2021年の単純平均差 (Difference-in-means) および、「\\(\\{\\)取引された物件の築年数 (Tenure)、 部屋の広さ (Size)、駅からの距離 (Distance to Station) \\(\\}\\) の分布が変化しなかった」という仮想シナリオのもとでの取引価格の平均差 (What if 分析) を信頼区間とともに表示\n5区 (中心6区: \\(\\{\\)中央/千代田/港/新宿/渋谷/本郷\\(\\}\\)、 北部: \\(\\{\\)北/板橋/豊島\\(\\}\\) 、南部: \\(\\{\\)品川/目黒/大田 \\(\\}\\) 、西部: \\(\\{\\)世田谷/中野/杉並/練馬 \\(\\}\\) 、 東部: \\(\\{\\) 台東/墨田/江東/葛飾/江戸川 \\(\\}\\))、 別の平均取引価格の上昇率 (物件の特徴はバランス済み)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>分析例</span>"
    ]
  },
  {
    "objectID": "stracture.html#分析例-取引価格の比較-1",
    "href": "stracture.html#分析例-取引価格の比較-1",
    "title": "1  分析例",
    "section": "1.5 分析例: 取引価格の比較",
    "text": "1.5 分析例: 取引価格の比較\n2022年と2021年の東京23区内の中古マンション市場を比較しました。\n\n2022-2021年比較: \\(\\{\\) Tenure, Size, Distance to Station \\(\\}\\)の差を95\\(\\%\\) 信頼区間 (Bonferoni法による修正済み)を表示\nバランス前-後平均取引価格上昇率: 取引価格の対数値について、2022年と2021年の単純平均差 (Difference-in-means) および、「\\(\\{\\)取引された物件の築年数 (Tenure)、 部屋の広さ (Size)、駅からの距離 (Distance to Station) \\(\\}\\) の分布が変化しなかった」という仮想シナリオのもとでの取引価格の平均差 (What if 分析) を信頼区間とともに表示\n5区 (中心6区: \\(\\{\\)中央/千代田/港/新宿/渋谷/本郷\\(\\}\\)、 北部: \\(\\{\\)北/板橋/豊島\\(\\}\\) 、南部: \\(\\{\\)品川/目黒/大田 \\(\\}\\) 、西部: \\(\\{\\)世田谷/中野/杉並/練馬 \\(\\}\\) 、 東部: \\(\\{\\) 台東/墨田/江東/葛飾/江戸川 \\(\\}\\))、 別の平均取引価格の上昇率 (物件の特徴はバランス済み)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>分析例</span>"
    ]
  },
  {
    "objectID": "stracture.html#意思決定",
    "href": "stracture.html#意思決定",
    "title": "1  分析例",
    "section": "1.6 意思決定",
    "text": "1.6 意思決定\n本ノートでは、何らかの意思決定問題の改善への活用を目指して行うデータ分析を想定します。 データ分析を始めるための最初のステップは、分析結果をどのような意思決定問題に活用するのか、明確なイメージを持つことです4。 活用方法に応じて、適した分析のゴール、ひいては分析方法も異なってきます。\nAgrawal, Gans, and Goldfarb (2018) は意思決定問題を、「予測と判断(Judgement)」に分解しています。 そして機械学習は予測の改善に役を立ち、人間により行われる判断を補完すると主張してます。 本ノートでは、機械学習や統計学、計量経済学の手法は、狭義の予測のみならず、広義の現状把握に役立つを強調します。 一般に意思決定において、社会や市場の状況について、包括的な状況把握が必要となります。 そして社会や市場の全てのを直接観察することはできず、過去の経験や事例から類推するしかありません。 具体例として、二つの意思決定問題を考え、これらの意思決定を支援するために、 ?fig-data のデータの活用を目指すとします。 便宜上、一番目の意思決定をミクロな意思決定、二番目をマクロな意思決定と呼びます。\n\n(ミクロな意思決定) 中古マンションの買取: 不動産業者が、ある中古マンションを適正価格で買取を行おうとしている。この際にこの物件の市場価格を参照したいが、分からない。\n(マクロな意思決定) 支店網の見直し: 大規模な不動産会社が、都内の支店網の見直し計画を策定しようとしている。この際に、足元の不動産市場の状況を参照したいが、分からない。\n\n本ノートにおいて、ミクロな意思決定は限られた範囲にのみ影響を与えるような意思決定を指します。 例えば、ある物件の買取が、他の物件に与える直接的な影響は限定的かもしれません。 一般に機械学習を用いた予測モデルの優れた実践例は、ミクロな意思決定の支援、あるいは自動化が多いです。 例えば、迷惑メールの自動分類が古典的な例となります。 このように影響を与える事例数が限られており、事例に合わせた意思決定が要求される場合、事例ごとに予測値を算出することには、大きな意義があります。\nミクロな意思決定については、予測値 ?fig-prediction は有益なものになるかもしれません。 予測性能が良ければ、買取査定において重要となる現状での市場価格を物件(事例)ごと に算出できます。\n対してマクロな意思決定は、幅広く影響を与えるような意思決定を指します。 政府による政策決定や企業の戦略決定、あるいは有権者による投票行動などが含まれます。 これらの意思決定は、影響を受ける利害関係者が多く、より複雑な判断を求められます。 この判断を支えるためには、影響を受ける事例群について、多角的な現状把握や決定の影響を予測する必要があります。\n個々の事例把握は困難であり、事例群全体の特徴を把握する方が現実的です。 影響を与える事例数が膨大なものとなる場合、マクロな意思決定については、予測値そのものの持つ意義は限定的です。 大量の予測値を一度に見せられても、人間が処理しきれず、判断に活用できないためです。 大量の取引物件(事例)の特徴 を、人間が把握するためには、より情報を要約する必要があり、 ?fig-description のような把握を目的とした結果が比較優位を有するかもしれません。 このような場合は、伝統的な推定方法、あるいは機械学習とのハイブリット的な方法が比較優位を持つと考えられます。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>分析例</span>"
    ]
  },
  {
    "objectID": "stracture.html#reference",
    "href": "stracture.html#reference",
    "title": "1  分析例",
    "section": "1.7 Reference",
    "text": "1.7 Reference\n\n\n\n\nAgrawal, Ajay, Joshua Gans, and Avi Goldfarb. 2018. Prediction Machines: The Simple Economics of Artificial Intelligence. Harvard Business Press.\n\n\n———. 2022. Power and Prediction: The Disruptive Economics of Artificial Intelligence. Harvard Business Press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>分析例</span>"
    ]
  },
  {
    "objectID": "stracture.html#footnotes",
    "href": "stracture.html#footnotes",
    "title": "1  分析例",
    "section": "",
    "text": "国土交通省のレポジトリ (https://www.reinfolib.mlit.go.jp/) からダウンロードできます。↩︎\nAgrawal, Gans, and Goldfarb (2018), Agrawal, Gans, and Goldfarb (2022)↩︎\n例えば国土交通省から平成31年に公表された 「先進的な技術の活用等により 多様化するニーズへ対応するための 不動産鑑定評価手法の在り方に関する検討業務」(https://www.mlit.go.jp/common/001285650.pdf) においては、不動産鑑定業務における有望な先進技術(12 ページ)として、「従来の基礎統計量の表示や重回帰分析等に基づく統計解析結果の出力はもちろん、ニューラルネットワークや決定木、主成分分析、クラスタリング、サポートベクトルマシンなど、より幅広い分析技術を身につけることにより、より丁寧な分析や詳細な説明を行うことができるようになると考えられる」と記載されている。↩︎\nAgrawal, Gans, and Goldfarb (2018), Agrawal, Gans, and Goldfarb (2022)↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>分析例</span>"
    ]
  },
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "2  要約の基本コンセプト",
    "section": "",
    "text": "2.1 観察できない変数が引き起こす問題\nデータから観察できない変数の存在は、あらゆる事例分析の最も深刻な問題の一つです。 このような変数への対処について、膨大な議論が蓄積されています。\n観察できない変数がもたらす問題は、個別事例分析において特に顕著です。 以下では、取引価格(Price; 単位 \\(=\\) 100万円) \\(=Y\\) と物件の特徴 \\(=X\\) の関係性を把握するために、個別事例を丹念に見ていきます。 例えば、以下の2億円で取引されている物件が、データの中に含まれていました。\nPrice\nSize\nTradeYear\nLargeDistrict\nTenure\n\n\n\n\n200\n105\n2022\n中心6区\n31\nこの事例から、部屋の広さが105平米で中心6区(港、中央、千代田、新宿、渋谷、文教)に立地する物件は、2億円で取引される傾向があったと結論づけても良いでしょうか？ ほとんどの応用でこのような推測は、不適切です。 実際に同じデータの中に、取引価格以外全く同じ特徴を持つ物件の取引事例が、以下の3件ありました。 これらの事例と比較すると、2億円はかなり高い価格での取引だったことがわかります。\nPrice\nSize\nTradeYear\nLargeDistrict\nTenure\n\n\n\n\n200\n105\n2022\n中心6区\n31\n\n\n150\n105\n2022\n中心6区\n33\n\n\n92\n105\n2022\n中心6区\n21\n\n\n110\n105\n2022\n中心6区\n30\nなぜこのような取引価格のブレが生じるのでしょうか？ データの誤入力など潜在的な理由は複数ありますが、有力なのはこのデータに含まれない重要な変数 が存在することです。 例えば、最寄駅や公園の近くにあるか否かなどのより詳細な立地情報が考えられます。 あるいは売り手や買い手の”交渉力”を反映している可能性もあります。 このような多様な要因が、取引価格に影響を与え、結果として事例の下振れ/上振れが生じます。\n観察できない変数は不動産のみならず、労働者や家計、企業、あるいは国レベルの分析でも同様の問題を引き起こします。 観察できる変数 \\(X\\) が一致した事例内でも、観察できない変数は事例間で大きく異なっている可能性が高く、結果 \\(Y\\) の値に大きな差が生まれます。 そして現実の社会や市場の複雑さを考慮すると、どれだけ詳細な調査（含むインタビュー調査や参与観察)を行ったとしても、\\(Y\\)に影響を与える全ての要因を観察することは困難です。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>要約の基本コンセプト</span>"
    ]
  },
  {
    "objectID": "model.html#観察できない変数が引き起こす問題",
    "href": "model.html#観察できない変数が引き起こす問題",
    "title": "2  要約の基本コンセプト",
    "section": "",
    "text": "2.1.1 コンセプト: 集計\n先の個別事例分析では、観察できない変数の偏りを確認する方法として、同じ\\(X\\)を持つ事例と比較しました。 このようなアプローチの発展として、同じ\\(X\\)を持つ事例集団について、\\(Y\\)の特徴を要約する方法があります。 例えば、平均値や分散、中央値、あるいは研究者による”所見”や”印象”、代表的な事例を紹介するなどです。\n恣意性の影響を緩和するために、調査計画を立てる時点で、要約方法も決定し、分析を通じてコミットすることが望まれます。 代表的な値の候補としては、中央値や最頻値など多くの候補があります。 現状よく用いられるのは、平均値の活用です。\n以下では、価格 (Price) と広さ (Size)、立地 (中心6区/その他)、取引年 (2021/2022)について、データに含まれる事例の分布をHeat mapで図示しています。\n\n\n\n\n\n\n\n\n\n上記の散布図は、社会分析に用いるデータの持つ典型的な特徴を表しています。 極めて乱雑であり、同じ\\(X\\) でも \\(Y\\) が異なる事例が多くなっています。 これは、観察できない変数の偏りが深刻である可能性を示唆しています。 また \\(X\\) の値に応じた事例数の偏りも顕著であり、特に100平米を超えるような物件の取引事例は少なくなっています。\n以下の各点は、各\\(X\\)の組み合わせごとに計算された平均値を図示しています。\n\n\n\n\n\n\nFigure 2.1: 平均値\n\n\n\n同図からは、\\(Y\\) と \\(X\\) のデータ上の関係性について、いくつか示唆を与えてます。 部屋が広くなると取引価格は高くなる傾向があり、この傾向は中心6区で特に顕著となります。\nしかしながら多くの応用では、このような\\(X\\)ごとに集計するだけでは、不十分です。 特に以下の問題に注意が必要です。\n\n\n2.1.2 集計の注意点\n\n2.1.2.1 少数事例の集計\n平均値は有力な要約方法ですが、算出に使用する事例の数に注意してください。 Figure 2.1 では、特に100平米を超える物件について少なくなっています。仮に平均値を計算するとしても、事例数が少ないと、各事例の観察できない変数の偏りの影響を強く受ける可能性があります。 この問題については、Section 2.2 で議論します。\n\n\n2.1.2.2 分析に含まれていない変数の問題\n\\(Y\\) 以外の変数についても、\\(X\\) 間で異なることに常に注意を払ってください。 Figure 2.1 がとらえる取引年、立地、部屋の広さと価格の関係性を解釈する際には、注意が必要です。 同図は、Sizeが増えると平均取引価格が上昇する傾向を示しますが、同時に築年数なども異なる可能性があります。 実際に築年数について、平均値を計算すると以下のようになりました。\n\n\n\n\n\n\n\n\n\nSize間で見られる取引価格の違いは、このような築年数の違いによっても、生じている可能性があります。 このような観察できる変数の違いについての対処は、Chapter 5 で議論します。\n観察できない変数の違いも取引価格に違いを与える可能性があります。 この問題については、万能の解決策は存在しません。 統計的因果推論などで、膨大な議論が存在ます。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>要約の基本コンセプト</span>"
    ]
  },
  {
    "objectID": "model.html#sec-Pop",
    "href": "model.html#sec-Pop",
    "title": "2  要約の基本コンセプト",
    "section": "2.2 観察できない事例が引き起こす問題",
    "text": "2.2 観察できない事例が引き起こす問題\n少数事例の集計が引き起こす問題を正確に理解するために、頻度論と呼ばれる枠組みを導入します1。 具体的なイメージを持つために、「自分と同じ課題に取り組む他の研究者達」を想像してください。 この研究者は、あなたと同じ社会を対象に同じ手法を用いて分析しています。 ただしデータは、独立して収集しているとします。 このような研究者達は、あなたと同じ分析結果に到達するでしょうか？\n簡単な理科の実験であれば、実験の手続きが同じであれば、誰がやっても同い結論に到達します。 例えば水の沸騰温度については、水に不純物を入れないなどを守れば、誰がやっても100度で沸騰します。 このため”科学的事実”に合意することが容易です。\n対して現実社会における多くの現象については、独立した研究者は、同じ結論に到達することは困難です。 なぜならば、分析に用いる事例が異なるためです。 ほとんどの応用で、独立して収集したデータが、完全に一致する可能性は無視できるほど小さくなるでしょう。 すなわちある研究者が観察した事例を、別の研究者は観察できない可能性が高いのです。\n分析結果の不一致の典型例としては、報道機関による世論調査が挙げられます。 複数の調査結果が、毎月公開されていますが、その結果は各社で異なっています。 理由は複数考えられますが、最も単純なものは、調査対象となる回答者が異なるためです。 典型的な世論調査では、各社が独立して電話番号をランダムに発生させるなどの方法で、1000-2000名ほどの回答者を極力ランダムに選んでいます。 しかしながら、異なる調査に同じ人が回答する確率は、非常に低くなります。\n観察できない事例の存在は、データにおける観察できない変数の偏りをもたらします。 ある研究者には、偶然、公園に近い物件の取引事例ばかり集まってくるかもしれません。 このような研究者のデータで計算された取引価格の平均値は、他の研究者と比べて、上振れる可能性が高いです。 すなわち要約した値であったとしても、研究者間で同じ値に合意できなくなります。\n事例研究において、人々が同じ結果を観察できない、という問題は深刻です。 なぜならば、「独立した個人や組織が同じ結果を観察できるので推定結果を事実として認定する」、という強力な枠組みが活用できません。 この問題に対処するためには、何らかの概念的な枠組みが必要となります。\n\n2.2.1 コンセプト: 母分布とサンプリング\n観察できない事例の問題と、それに伴う分析結果の不一致の問題を適切に論じるために、母分布という分析概念を導入します。 母集団を導入することで、共通の正答と各々のデータから得られる回答が、分離して定義できます。\n「私たちが手にしているデータは、母集団という無数の事例の集団から、選ばれた事例から構成されている」と 想定 します。 さらに本ノートでは、事例は完全ランダムに選ばれていると仮定します。 このような仮定をランダムサンプリングと呼ばれます。\n私たちが得られる回答は、このランダムに選ばれた一部の事例のみから得たものであり、正答とは一致しません。\n例えば日本全体のすべての家計が母集団であり、母集団における夫婦間の平均的な家事分担を知りたいとします。 この場合、正答はすべての家計を調査し尽くせば得ることができます。 対して私たちのデータは、家計全体の一部であり、そこから得られる回答（例えば、データ上の平均的な分担）は、母集団における正答とは異なります。 極端な場合として、日本全体では妻の方が夫よりも家事負担が大きかったとしても、データに含まれる事例が偶然偏り、回答としては夫の家事負担がより大きいという結果を得る可能性があります。\n母集団として、仮想的な集団を想定することもできます。 例えば、あるコンビニのレジデータに、ある日の全ての来客者について、購入金額が全て記録されているとします。 この場合、現実の来客者全てが記録されているため、母集団は存在しないと考えることも可能です。 一方で、その日にコンビニを訪れた顧客は、潜在的な顧客の一部であると想定することもできます。 皆さんも、よく利用するコンビニであったとしても、毎日利用しないのではないでしょうか？ この場合の母集団は、潜在的な顧客となります。\n母集団を想定すると、母集団における変数の分布も定義できます。 例えば、「取引物件の母集団において、中心6区に立地する物件の割合は2割」、といった感じです。 また母分布を定義できれば、そこから母集団における平均値(母平均)も定義できます。 平均値の推定を目指す研究であれば、この母平均が正答となります。 例えば、「中心6区に立地する50平米の中古マンションの2022年における平均取引価格は5000万円」、といった感じです。\n何を正答するかは、推定対象、ひいては活用したい意思決定問題に応じて、人間が適切に設定する必要があります。 本ノートは、多くの予測/社会の把握を目的とした分析において、母平均は正答となることを論じます。 同時に、データから回答を得る方法は、目的に応じて大きく異なることも強調します。\n注意が必要なのは、「我々には母分布や母平均を正確に知ることは不可能である」ことがデータ分析法の前提である点です。 知ることができない母分布や母平均を、手元にある限られたデータから、以下に推測するのかが、データ分析の中心的な挑戦となります。 データが母集団の一部であり、観察できていない事例が存在する以上、データ上の平均値と母平均は一致しません。 またデータはランダムに選ばれているので、独立した研究者間で、平均値について厳密な合意はできません。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>要約の基本コンセプト</span>"
    ]
  },
  {
    "objectID": "model.html#sec-Sim",
    "href": "model.html#sec-Sim",
    "title": "2  要約の基本コンセプト",
    "section": "2.3 数値例",
    "text": "2.3 数値例\n以上の概念を明確にするために、簡単な数値実験を行います。 今、4名の研究者が独立して20事例を集めたとします。 各事例について、取引価格 \\(Y\\) と 部屋の広さ \\(X\\) がデータから観察できるとします\n母分布は以下のように設定しています。\n\n部屋の広さは、\\(X\\in\\{30,35,40,..,80\\}\\) が同じ割合で存在\n取引価格は、\n\n立地が中心6区ではなく部屋の広さが75以下であれば \\[50 + 0.1 \\times X + 0.001 \\times Size^2\\]\n立地が中心6区、または、部屋の広さが75以上であれば \\[55 + 0.1 \\times X + 0.001 \\times Size^2\\]\n立地が中心6区、かつ、部屋の広さが75以上であれば \\[60 + 0.1 \\times X + 0.001 \\times Size^2\\]\n\n\n以下の図は、4名の研究者が手にするデータと平均値を図示しています。\n\n\n\n\n\n\n\n\n\n平均値について、研究者間で大きな違いが見られます。\nこの図に母平均を上書きすると以下のようになります。 ただし図を簡略化するために、各事例の値は排除します。\n\n\n\n\n\n\n\n\n\n重要な点として、母平均とデータ上の平均は乖離していることを確認してください。 また乖離の仕方は、研究者によって異なります。 言い換えるならば、母平均は全員共通である一方で、データ上の平均値は異なっています。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>要約の基本コンセプト</span>"
    ]
  },
  {
    "objectID": "model.html#reference",
    "href": "model.html#reference",
    "title": "2  要約の基本コンセプト",
    "section": "2.4 Reference",
    "text": "2.4 Reference\n\n\n\n\nLin, Hanti. 2024. “To Be a Frequentist or Bayesian? Five Positions in a Spectrum.” Harvard Data Science Review 6 (3).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>要約の基本コンセプト</span>"
    ]
  },
  {
    "objectID": "model.html#footnotes",
    "href": "model.html#footnotes",
    "title": "2  要約の基本コンセプト",
    "section": "",
    "text": "頻度論以外にはベイズ法と呼ばれる枠組みもあります。Lin (2024)などを参照ください。↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>要約の基本コンセプト</span>"
    ]
  },
  {
    "objectID": "prediction.html",
    "href": "prediction.html",
    "title": "3  予測を目的とする要約",
    "section": "",
    "text": "3.1 推定目標\n本ノートでは、データと同じ母集団から新たに抽出された事例を、予測するモデルの推定を目指します。 予測能力は、平均事情誤差で測定します \\[母集団における平均二乗誤差 = (Y - 予測値)^2 の母集団における平均\\] 注意が必要なのは、母集団における平均二乗誤差は、母集団上の値であり、直接観察することは不可能です。 ただし本章で紹介する通り、推定することは可能です。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>予測を目的とする要約</span>"
    ]
  },
  {
    "objectID": "prediction.html#推定目標",
    "href": "prediction.html#推定目標",
    "title": "3  予測を目的とする要約",
    "section": "",
    "text": "3.1.1 完璧な予測モデル\n予測研究における究極的な目標の一つは、 \\(Y\\) を完璧に予測するモデルの推定です。 しかしながら多くの応用で、この目標には到達することができません。 予測モデルは、ある\\(X\\)の組み合わせについて、一つの予測値のみを出力します。 このため母集団において、同じ\\(X\\) 内で\\(Y\\) の値にばらつきがあれば、予測が外れる事例は必ず存在します。\n完璧な予測には、\\(Y\\)の全ての決定要因を\\(X\\)として観察し、\\(X\\)内での個人差をなくす必要があります。 しかしながら人間行動や社会的な事象などの社会的変数の決定要因は無数に存在し、その多くは観察が難しいと考えられます。 結果、社会的変数について、完璧な予測は不可能と考えられます。\n\n\n3.1.2 理想の予測モデル\n最も高い予測性能 (母集団における平均二乗誤差が最小化)を達成する予測モデルは、母平均であることが証明できます \\[理想の予測モデル = X内でのYの母平均\\]\n予測研究においては、データから推定した予測モデルを理想の予想モデルである母平均に極力近づけることが、実質的な目標となります。 具体的には以下の予測誤差を極力削減することを目指します \\[(\\underbrace{X内でのYの母平均}_{理想の予測モデル}-予測モデル)^2の母平均\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>予測を目的とする要約</span>"
    ]
  },
  {
    "objectID": "prediction.html#推定方法",
    "href": "prediction.html#推定方法",
    "title": "3  予測を目的とする要約",
    "section": "3.2 推定方法",
    "text": "3.2 推定方法\n手元のデータから、母平均を推定するため方法として、二つの極端な方法を紹介し、その中間的な方法として線型モデルを最小二乗法(OLS)で紹介するアプローチ、およびその発展として罰則付き回帰 (ここではLASSO)を紹介します。\n\n3.2.1 learning by memorization (丸暗記法)\nデータ上の\\(Y\\)の平均値を予測モデルを推定する方法であり、learning by memorization (丸暗記法) とも呼ばれます。 この方法は、\\(X\\) の各組み合わせについて、十分な事例数があれば、実用的な方法です。 なぜならば、データ上での平均値と母平均が近い値となることが期待できるためです。\nしかしながらほとんどの応用で、事例数の少ない \\(X\\) の組み合わせが存在します。 このような場合、データ上の平均値は、母平均からかけ離れた値となってしまいます。\nSection 2.3 の数値例を用いた予測モデルは、以下となります。\n\n\n\n\n\n\n\n\n\n点線が母平均、実線が丸暗記法が生み出した予測値となります。 母平均と予測値が、大きく乖離するグループが散見されます。 このような乖離は、データが母平均よりも上振れ/下振れしたケースにおいて、見られることも確認できます。\n\n\n3.2.2 単純平均\n少数事例の要約を避けるためには、より”荒い”要約が必要となります。 最も極端な方法は、\\(Y\\) のデータ全体での単純平均を予測値とする方法です。\n数値例は以下です。\n\n\n\n\n\n\n\n\n\n単純平均法では、予測値は\\(X\\)の値に依存せずに一定です。 このため丸暗記法に比べて、予測モデルが単純化されてると言えます。 ただし\\(X\\) と \\(Y\\) の母平均との間での関係性を一切無視した集計になっており、依然として母平均との乖離が生じています。\n\n\n3.2.3 OLS\n多くの実践において、丸暗記法と単純平均法の中間的な要約が有効です1。 なぜならば丸暗記法は、複雑なモデルの推定を試みており、母平均から乖離した事例の影響を受けやすく、単純平均法は単純すぎるモデルの推定を行なっており、母平均の特徴の多くを無視しているためです。\n単純平均と丸暗記法の中間的なモデルを推定する代表的な方法は、研究者が事前に設定した線型モデルを最小二乗法 (OLS) で推定する方法です。\n\n\n\n\n\n\nOLSの定義\n\n\n\n\n研究者が予測モデルの大枠を以下のように設定する \\[予測モデル=\\beta_0 + \\beta_1X_1 + \\beta_2X_2 +.. + \\beta_LX_L\\]\n以下を最小化するように \\(\\beta_0,..,\\beta_L\\) を決定する \\[(Y-予測モデル)^2のデータ上の平均\\]\n\n\n\nOLSは、研究者が事前に大枠を設定した予測モデルを、データに最も合うように推定する手法であると解釈できます。\n\n3.2.3.1 単回帰\n最もシンプルな線型モデルとして、例えば以下を推定してみます。 \\[予測値 = \\beta_0 + \\beta_1\\times Size\\] \\(\\beta_0,\\beta_1\\) は、以下のデータ上の平均二乗誤差を最小化するように推定します。\\[(Y - 予測値)^2 のデータ上の平均\\] このような推定方法は、単回帰として教科書では紹介されてきました。\n推定結果を図示すると、以下となります。\n\n\n\n\n\n\n\n\n\n単純平均とは異なり、広い物件は取引価格が高くなる傾向を捉えることができています。 さらに丸暗記法ほど、母平均から大きく乖離した予測も見られません。 これは丸暗記法と比べて、事例の要約が機能していることを表しています。\nしかしながら母平均に比べると、以前として単純すぎます。 特に立地に応じて、平均価格が異なるという性質を捉えきれていません。\n\n\n3.2.3.2 重回帰\nDistrictと平均取引価格の関係性を捉えるために、以下のモデルの推定を試みます。 \\[予測値 = \\beta_0 + \\beta_1\\times Size + \\beta_2\\times District\\] \\(District\\) は、中心６区に立地していれば1、それ以外では0を取ります。 \\(\\beta_0,..,\\beta_2\\) は引き続き、データへの適合度を最大化するように推定できます。 このような推定方法は、重回帰として教科書では紹介されてきました。\n推定結果を図示すると、以下となります。\n\n\n\n\n\n\n\n\n\n中心6区の方が平均取引価格が高いという性質を上手く捉えています。 しかしながら、Sizeが70平米を超えると、取引価格が一段上昇するという性質は捉えきれていません。\n\n\n3.2.3.3 交差項と高次項の導入\n母平均が持つ複雑な性質を捉えるために、交差効果と高次項を導入し、さらに複雑なモデルを推定してみます。 \\[予測値 = \\beta_0 + \\beta_1 Size+\\beta_7District + \\underbrace{\\beta_2Size^2 +..+\\beta_6Size^6}_{高次項}\\] \\[+\\underbrace{\\beta_8 Size\\times District +..+\\beta_{14}Size^6\\times District}_{交差効果}\\] このような複雑なモデルであったとしても、データへの適合度を最大化するように推定できます。\n\n\n\n\n\n\n\n\n\n複雑なモデルを最小二乗法で推定すると、よりデータへの適合度を改善し、データ上の平均値に近づけることができます。 しかしながらここまで議論してきた通り、このことは必ずしも望ましいとはいえません。 なぜならば、丸暗記法により推定されたモデルに近づくからです。 少数の事例しかない\\(X\\)の組み合わせについては、丸暗記法と同様に母平均から乖離し、予測性能が悪化します。\n線型モデルを複雑にしすぎると丸暗記モデルになり、単純化しすぎると単純平均モデルとなります。 この中間的なモデルが予測性能が高いことが多いですが、分析者がそのようなモデルを適切に設定することは困難です。 機械学習では、この問題に対して、データに基づく解決策を提案しています。\n\n\n\n3.2.4 LASSO\n適切な単純さをもつモデルを推定する方法として、LASSO (Tibshirani 1996) を紹介します。 LASSOは、罰則付き回帰と呼ばれる枠組みの一つの手法です。 OLSと同様に線型予測モデルを推定しますが、データへの当てはまりだけでなく、モデルの複雑性も抑制することも目指します。\n例えば、以下のモデルを推定します。\\[予測値 = \\beta_0 + \\beta_1 Size+\\beta_7District + \\underbrace{\\beta_2Size^2 +..+\\beta_6Size^6}_{高次項}\\] \\[+\\underbrace{\\beta_8 Size\\times District +..+\\beta_{14}Size^6\\times District}_{交差効果}\\] \\(\\beta\\) の値は、以下を最小化するように決定します。 \\[(Y - 予測値)^2 のデータ上の平均\\] \\[+ \\underbrace{\\lambda}_{Tunning\\ Parameter} (\\beta_1の絶対値 +..)\\] \\(\\lambda\\) は、データへの当てはまりではなく、モデルの予測性能を高めるように決定します。 具体的には、交差検証を用いる方法、情報基準などの理論的な評価指標を用いる方法があります。\n\n\n\n\n\n\nNote\n\n\n\n\\(\\lambda\\) は、\\(\\beta\\) と異なり、データへの当てはまりを最大化するように決定できません。 なぜでしょうか？\n\n\n\\(\\lambda\\) に応じて、予測モデルがどのように変化するのか考えてみます。 \\(\\lambda\\) を変化させることで、予測モデルは、単純平均と丸暗記の間で変化することになります。 \\(\\lambda=0\\) であれば、OLSと全く同じモデルを推定します。 よって、複雑な線型モデルを推定した場合は丸暗記モデルに近いモデルとなります。 \\(\\lambda\\) を非常に大きい値を設定した場合、\\(\\beta_1=\\beta_2=..= 0\\) となります。 この場合は\\(\\beta_0\\)をデータに当てはまるように推定することになり、単純平均と一致します。\n\n\n\n\n\n\n\n\n\nDistrictとSizeについて、直線のモデルが推定されており、モデルが単純化されていることが確認できます。\n\n3.2.4.1 事例数の拡大\n推定結果は、一般に事例数に強く影響を受けます。 特にLASSOなどの機械学習の方法においては、データの特徴により強く依存します。\n以下の数値例では、事例数を200事例から50000事例まで増やし、 \\(Y\\sim Size + District\\) をOLSで、\\(Y\\sim (Size + Size^2 + .. + Size^6) * District\\) をLASSOで推定しています。\n\n\n\n\n\n\n\n\n\n上記結果は、事例数が拡大すると、サンプル平均と母平均の乖離が減少していることが確認できます。 さらにLASSOとサンプル平均との乖離も減少しており、結果、LASSOが母平均を上手く近似できていることが確認できます。 対して単純なモデルのOLS推定は、分析者が設定したモデルに推定結果が大きく制約されており、事例数増加の恩恵が十分に得られません。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>予測を目的とする要約</span>"
    ]
  },
  {
    "objectID": "prediction.html#予測性能の測定",
    "href": "prediction.html#予測性能の測定",
    "title": "3  予測を目的とする要約",
    "section": "3.3 予測性能の測定",
    "text": "3.3 予測性能の測定\n予測を目指す分析では、推定された予測モデルの性能を評価することが重要となります。 現状、幅広いデータや状況において、一貫して高い予測性能を生み出す方法は存在しません。 このため複数の予測モデルを”試作”し、その性能を比較することが分析工程に組み込まれています。\n最もシンプルな評価方法は、サンプル分割です。\n\n\n\n\n\n\nサンプル分割法の定義\n\n\n\n\nデータをランダムに訓練データとテストデータに分割する\n\n\n訓練/テスト間での事例数の比率については、8対2や95対5が(経験則として)推奨されることが多い。\n\n\n訓練データのみでモデルを試作する\nテストデータへの当てはまりを(平均二乗誤差などで)評価する\n\n\n\n実際の取引データに適用した結果は以下です。 6378事例のうち、ランダムに選んだ半分を訓練、残り半分をテストに用いました。 テストした推定方法は以下です。\n\nOLS: 取引価格 ~ 部屋の広さ + 立地 + 取引年\nOLS (含む交差項 + 高次項): 取引価格 ~ 部屋の広さ + 立地 + 取引年 + 交差項 + 高次項(６次まで)\nLASSO (含む交差項 + 高次項): 取引価格 ~ 部屋の広さ + 立地 + 取引年 + 交差項 + 高次項(６次まで)\n\n推定された予測モデルの評価結果は以下となりました。\n\n\n\n\n\n\n\n\nOLS\nOLS| 交差項 + 高次項\nLASSO\n\n\n\n\n369\n316\n303\n\n\n\n\n\n\n\nLASSOが最も予測性能が高く、単純なOLSと比較し、0.179 パーセントほど平均二乗誤差を削減しています。 対して、交差項と高次項を追加したOLSとLASSOを比較した場合、0.041 パーセントほどの改善にとどまります。 これはモデルの複雑さに比べて、事例数が多く、LASSOによるモデル単純化の恩恵が限定的であることを示しています。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>予測を目的とする要約</span>"
    ]
  },
  {
    "objectID": "prediction.html#まとめ",
    "href": "prediction.html#まとめ",
    "title": "3  予測を目的とする要約",
    "section": "3.4 まとめ",
    "text": "3.4 まとめ\n\n他の予測モデルの推定方法については、James et al. (2021) 参照\n予測誤差の他の測定方法については、Angelopoulos, Bates, et al. (2023) などを参照",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>予測を目的とする要約</span>"
    ]
  },
  {
    "objectID": "prediction.html#rによる実践例",
    "href": "prediction.html#rによる実践例",
    "title": "3  予測を目的とする要約",
    "section": "3.5 Rによる実践例",
    "text": "3.5 Rによる実践例\n\n以下のパッケージを使用\n\nreadr (tidyverseに同梱): データの読み込み\nhdm: LASSO\n\n\n\n3.5.1 準備\nデータとその事例数を取得し、データをランダムに分割します。\n\nData = readr::read_csv(\"Public.csv\") # データ読み込み\n\nN = nrow(Data) # 事例数の取得\n\nGroup = sample(\n  1:2,\n  N, # 事例数\n  replace = TRUE, # 復元抽出を指定\n  prob = c(0.8,0.2) # \"1\"が8割、\"2\"が２割\n) # サンプル分割のために1または2をランダムに発生\n\nTrain = Data[Group == 1,] # 訓練データ\nTest = Data[Group == 2,] # テストデータ\n\nlm関数を用いてOLS, hdmパッケージ内のrlasso関数を用いてLASSO推定をします。 またLASSO推定は、複雑なモデルを推定に利点を持つため、交差項と二乗項までを導入したモデルも推定しています。\n\nOLS = lm(Price ~ Size + Tenure + District + StationDistance,\n         Train) # OLS\n\nLASSO = hdm::rlasso(Price ~ Size + Tenure + District + StationDistance,\n                    Train) # LASSO\n\nLASSO_Long = hdm::rlasso(\n  Price ~ (Size + Tenure + District + StationDistance)**2 +\n    poly(Size,2) + poly(Tenure,2) + poly(StationDistance,2),\n  Train) # LASSO (含む二乗項と交差項)\n\nLASSOで推定されたモデルで使用される変数リストは、以下で表示できます。 Trueが選択された変数です。\n\nLASSO$index\n\n            Size           Tenure   District中央区   District中野区 \n            TRUE             TRUE             TRUE             TRUE \n    District北区 District千代田区   District台東区   District品川区 \n            TRUE             TRUE            FALSE            FALSE \n  District大田区   District文京区   District新宿区   District杉並区 \n            TRUE             TRUE             TRUE             TRUE \n  District板橋区 District江戸川区   District江東区   District渋谷区 \n            TRUE             TRUE             TRUE             TRUE \n    District港区   District目黒区   District練馬区   District荒川区 \n            TRUE             TRUE             TRUE             TRUE \n  District葛飾区   District豊島区   District足立区   District墨田区 \n            TRUE            FALSE             TRUE             TRUE \n StationDistance \n            TRUE \n\n\nテストデータを用いて推定された平均二乗誤差は以下です。\n\nmean((Test$Price - predict(OLS,Test))^2)\n\n[1] 240.7735\n\nmean((Test$Price - predict(LASSO,Test))^2)\n\n[1] 242.2394\n\nmean((Test$Price - predict(LASSO_Long,Test))^2)\n\n[1] 200.474\n\n\n二乗項と交差項を含めたモデルをLASSOで推定した予測モデルが、予測性能が最も高くなりました。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>予測を目的とする要約</span>"
    ]
  },
  {
    "objectID": "prediction.html#reference",
    "href": "prediction.html#reference",
    "title": "3  予測を目的とする要約",
    "section": "3.6 Reference",
    "text": "3.6 Reference\n\n\n\n\nAngelopoulos, Anastasios N, Stephen Bates, et al. 2023. “Conformal Prediction: A Gentle Introduction.” Foundations and Trends in Machine Learning 16 (4): 494–591.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, et al. 2021. An Introduction to Statistical Learning. Vol. 112. Springer.\n\n\nSpiess, Jann, Amar Venugopal, et al. 2024. “Double and Single Descent in Causal Inference with an Application to High-Dimensional Synthetic Control.” Advances in Neural Information Processing Systems 36.\n\n\nTibshirani, Robert. 1996. “Regression Shrinkage and Selection via the Lasso.” Journal of the Royal Statistical Society Series B: Statistical Methodology 58 (1): 267–88.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>予測を目的とする要約</span>"
    ]
  },
  {
    "objectID": "prediction.html#footnotes",
    "href": "prediction.html#footnotes",
    "title": "3  予測を目的とする要約",
    "section": "",
    "text": "異なるのアプローチは、Spiess, Venugopal, et al. (2024) などを参照↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>予測を目的とする要約</span>"
    ]
  },
  {
    "objectID": "simplecomparison.html",
    "href": "simplecomparison.html",
    "title": "4  把握を目的とする要約: 単純な比較",
    "section": "",
    "text": "4.1 推定対象",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>把握を目的とする要約: 単純な比較</span>"
    ]
  },
  {
    "objectID": "simplecomparison.html#推定対象",
    "href": "simplecomparison.html#推定対象",
    "title": "4  把握を目的とする要約: 単純な比較",
    "section": "",
    "text": "4.1.1 平均差\nもし\\(D\\) が少数のカテゴリー (中心6区 VS その他)を表すのであれば、 \\(D\\) と \\(Y\\) の関係性を要約する代表的な指標は、\\(Y\\) の平均差です \\[D=1におけるYの平均 - D=0におけるYの平均\\]\n\n\n4.1.2 補助線\n\\(D\\) が整数や実数 (部屋の広さ)を表す場合であったとしても、原理的には母平均の差を定義することは可能ですが、推定することは困難です。 これは全く同じ\\(D\\)の値をとる事例数が少なすぎるためです。 この問題への対処としては、母平均そのものではなく、その補助線(Best Linear Projection)を推定することが有力です。 \\[Yの平均値のモデル= \\underbrace{\\beta_0+\\beta_1\\times d}_{Best Linear Projection}\\] \\(\\beta_0,\\beta_1\\) は、以下を最小化する値として定義します \\[(D=dにおけるYの平均-Best\\ Linear\\ Projection)^2の平均値\\] このようなモデルは、母集団上でOLS推定を仮想的に行った結果得られるモデルと完全に一致します。 このためPopulation OLS (母集団上でのOLS)と呼ばれることもあります。\n注意点は、母集団上で仮想的に定義されたモデルであるという点です。 分析者は、このモデルを直接観察できず、データから推定する必要があります(後述のように、このような線型モデルは容易に推定できます。)。 言い換えると、分析課題に適した推定対象を定義するために導入されたモデルです。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>把握を目的とする要約: 単純な比較</span>"
    ]
  },
  {
    "objectID": "simplecomparison.html#推定方法",
    "href": "simplecomparison.html#推定方法",
    "title": "4  把握を目的とする要約: 単純な比較",
    "section": "4.2 推定方法",
    "text": "4.2 推定方法\n\n4.2.1 モーメント法\n平均差やBLPの最も単純かつ優れた推定方法は、推定対象の母集団上での定義を、データに適用することです。 例えば、平均差については、\\(D=1\\) および \\(D=0\\) それぞれについて、\\(Y\\) のデータ上での平均値を計算し、その差を求めます1。 BLPについても、データ上で、\\(Y\\)を\\(D\\)でOLS推定した結果を推定値として用いることができます。\nこのような推定方法は、モーメント法と呼ばれます。2。\n\n\n4.2.2 信頼区間\nモーメント法が持つ大きな利点は、ある程度の事例数を持つランダムサンプリングデータであれば、推定値とEstimandの関係性について、近似的な性質が成り立つ点です。\nデータ上の単純平均値やOLSの結果であったとしても、データの偶然の偏りの影響は受けます。 このため、一般にデータから得た推定値は母平均と一致しません。 言い換えるならば、「推定値を母平均である」と強弁すると、ほぼ100\\(\\%\\)間違いを犯していることになります。\n多くの学術研究では、より信頼できる分析結果として、推定の精度を表す指標を合わせて報告します。 本ノートでは、代表的な指標である信頼区間を紹介します3。 信頼区間を端的に定義すると、 一定の確率(多くの初期設定で 95 \\(\\%\\)) でEstimandを含む区間です。\nより正確なイメージを持つために、仮想的な研究者を再度イメージしてください。 以下の数値例では、合計36名の研究者を想像し、それぞれが独立してデータを収集し、\\(95\\%\\)信頼区間を計算しています。 Estimand (母平均) は0.5、一様分布からそれぞれ500事例収集しています。\n\n\n\n\n\n\n\n\n\n期待値通り２名の 分析者(22と35)について、信頼区間がEstimandを明確に含まない結果となりました。\n推定誤差の提示は、透明性を高めるためにも非常に重要です。 把握のための分析が特に求められるのは、企業戦略や政策決定などの、マクロな意思決定です。 これらの意思決定は、幅広い層に不可逆的な影響を与えることが多く、決定過程に対して透明性が求められます。 このためその判断材料となる情報にも、高い信頼性が求められます。 この点において、モーメント法は大きな利点を有します4。\n\n\n4.2.3 「予測値の集計」の問題点\nモーメント法の代替となる推定方法として、機械学習で推定した予測値を用いる方法があります。 例えば全ての事例について、予測値を算出し、その予測値の平均値を\\(D=0\\) と \\(1\\) それぞれについて算出し、差を計算します。\n信頼区間など、母集団の特徴についての推定誤差を導出したい場合、この方法は、一般に推奨されません。 なぜならば、機械学習を用いた推定方法では、データと推定結果の関係性が複雑であり、一般的な関係性が不透明なためです。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>把握を目的とする要約: 単純な比較</span>"
    ]
  },
  {
    "objectID": "simplecomparison.html#rによる実践例",
    "href": "simplecomparison.html#rによる実践例",
    "title": "4  把握を目的とする要約: 単純な比較",
    "section": "4.3 Rによる実践例",
    "text": "4.3 Rによる実践例\n\n以下のパッケージを使用\n\nreadr (tidyverseに同梱): データの読み込み\nestimatr: OLS + Robust confidence interval\n\n\n\n4.3.1 準備\nデータを取得します。 シンプルな比較分析について信頼区間は、データ分割を用いずに算出できます。\n\nData = readr::read_csv(\"Public.csv\") # データ読み込み\n\n\n\n4.3.2 推定\nestimatrパッケージ内のlm_robust関数を用いてOLS推定をします。 信頼区間も同時に計算できます。\n例えば立地別の平均取引価格とその信頼区間は、以下で計算できます。\n\nestimatr::lm_robust(\n  Price ~ District,\n  Data,\n  alpha = 0.05 # 信頼水準\n)\n\n                   Estimate Std. Error    t value      Pr(&gt;|t|)    CI Lower\n(Intercept)       49.544882   1.350350  36.690388 1.745377e-267  46.8977395\nDistrict中央区     7.091314   2.187476   3.241779  1.193986e-03   2.8031236\nDistrict中野区    -9.856420   2.086807  -4.723206  2.371427e-06 -13.9472663\nDistrict北区     -12.876540   1.816387  -7.089094  1.495990e-12 -16.4372719\nDistrict千代田区   5.356645   4.530838   1.182264  2.371454e-01  -3.5253261\nDistrict台東区   -11.194472   1.939907  -5.770622  8.270181e-09 -14.9973450\nDistrict品川区    -5.324154   2.040205  -2.609616  9.085635e-03  -9.3236446\nDistrict大田区   -19.161899   1.541545 -12.430320  4.562932e-35 -22.1838471\nDistrict文京区    -6.367891   2.245219  -2.836201  4.579809e-03 -10.7692765\nDistrict新宿区    -3.701065   1.974378  -1.874547  6.090085e-02  -7.5715111\nDistrict杉並区   -11.398479   2.003932  -5.688056  1.342130e-08 -15.3268624\nDistrict板橋区   -19.166705   1.544366 -12.410730  5.795223e-35 -22.1941827\nDistrict江戸川区 -14.379365   1.700541  -8.455761  3.404197e-17 -17.7129980\nDistrict江東区    -4.449929   1.693359  -2.627871  8.612771e-03  -7.7694837\nDistrict渋谷区     8.621508   3.150562   2.736498  6.226950e-03   2.4453432\nDistrict港区      27.616087   3.626363   7.615368  3.012509e-14  20.5071929\nDistrict目黒区     4.924307   2.471150   1.992719  4.633491e-02   0.0800203\nDistrict練馬区   -18.367485   1.669575 -11.001297  6.716948e-28 -21.6404139\nDistrict荒川区   -14.102733   2.059536  -6.847529  8.218814e-12 -18.1401184\nDistrict葛飾区   -20.518000   1.671244 -12.277082  2.932896e-34 -23.7942022\nDistrict豊島区   -13.685211   2.125035  -6.439992  1.282187e-10 -17.8509972\nDistrict足立区   -20.680762   1.542884 -13.403964  2.021371e-40 -23.7053355\nDistrict墨田区   -13.869062   1.675184  -8.279127  1.498715e-16 -17.1529884\n                    CI Upper   DF\n(Intercept)       52.1920243 6355\nDistrict中央区    11.3795053 6355\nDistrict中野区    -5.7655744 6355\nDistrict北区      -9.3158085 6355\nDistrict千代田区  14.2386157 6355\nDistrict台東区    -7.3915991 6355\nDistrict品川区    -1.3246626 6355\nDistrict大田区   -16.1399503 6355\nDistrict文京区    -1.9665050 6355\nDistrict新宿区     0.1693818 6355\nDistrict杉並区    -7.4700956 6355\nDistrict板橋区   -16.1392275 6355\nDistrict江戸川区 -11.0457313 6355\nDistrict江東区    -1.1303735 6355\nDistrict渋谷区    14.7976731 6355\nDistrict港区      34.7249806 6355\nDistrict目黒区     9.7685943 6355\nDistrict練馬区   -15.0945553 6355\nDistrict荒川区   -10.0653478 6355\nDistrict葛飾区   -17.2417981 6355\nDistrict豊島区    -9.5194250 6355\nDistrict足立区   -17.6561890 6355\nDistrict墨田区   -10.5851361 6355\n\n\nEstimateが推定値、CI lower/CI upperが信頼区間の下限/上限を表します。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>把握を目的とする要約: 単純な比較</span>"
    ]
  },
  {
    "objectID": "simplecomparison.html#reference",
    "href": "simplecomparison.html#reference",
    "title": "4  把握を目的とする要約: 単純な比較",
    "section": "4.4 Reference",
    "text": "4.4 Reference\n\n\n\n\nImbens, Guido W. 2021. “Statistical Significance, p-Values, and the Reporting of Uncertainty.” Journal of Economic Perspectives 35 (3): 157–74.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>把握を目的とする要約: 単純な比較</span>"
    ]
  },
  {
    "objectID": "simplecomparison.html#footnotes",
    "href": "simplecomparison.html#footnotes",
    "title": "4  把握を目的とする要約: 単純な比較",
    "section": "",
    "text": "平均差による母平均の差の推定結果は、以下の母平均のモデルをOLSで推定した結果と一致とします。 \\[Y=\\beta_0 + \\underbrace{\\beta_1}_{=E[Y|D=1] - E[Y|D=0]}D + \\underbrace{u}_{E[u|D=1]=E[u|D=0]=0}\\]↩︎\n他の推定方法として、最尤法やベイズ法があります。これらの手法は、モーメント法よりも強い仮定を要求しますが、その仮定が正しいのであれば、推定精度が高くなります。↩︎\n信頼区間の問題点と代替的な評価指標について、例えば Imbens (2021) などを参照してください。↩︎\n事例数が少ないケースにおいては、モーメント法の有用性は大きく低下します。このような場合は、ベイズ法などが有力な選択肢となります。↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>把握を目的とする要約: 単純な比較</span>"
    ]
  },
  {
    "objectID": "complexcomparison.html",
    "href": "complexcomparison.html",
    "title": "5  把握を目的とする要約: Balanced Comparison",
    "section": "",
    "text": "5.1 実例",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>把握を目的とする要約: Balanced Comparison</span>"
    ]
  },
  {
    "objectID": "complexcomparison.html#実例",
    "href": "complexcomparison.html#実例",
    "title": "5  把握を目的とする要約: Balanced Comparison",
    "section": "",
    "text": "5.1.1 不動産市場の年次比較\n例えば、2022年と2021年の東京２３区の中古マンション市場における、取引価格と立地(中心6区かそれ以外か)について平均的な差は以下の通りです。\n\n\n\n\n\n\n\n\n\n2022年においては、平均取引価格が2021年に比べて上昇していますが、同時に中心６区の物件割合も増加しています。 一般に中心６区の物件の方が取引価格が高い傾向が予想されるので、その分取引価格の上昇が”底上げ”されている可能性があります。 もし中心6区の物件割合が不変であった場合、平均取引価格にどのような差が残るでしょうか？\nこのような問いに対して、バランス後の比較分析は回答できます。\n\n\n5.1.2 合計特殊出生率\n合計特殊出生率の国家間/時代間比較は、バランス後の比較の代表例です。 出生数の動向を把握する上で、新生児数を年次や国家間比較は、有益だとみなされてきました。 合計特殊出生率 は、成人の年齢構造の違いをバランスさせるために利用されている指標です。 単純な出生率（一年間に生まれた子供の数/女性の数）は、成人の年齢構造の影響を強く受ける可能性があります。 比較的高齢の成人の比率が高まれば、出生率は低下することが予想されるからです。 対して合計特殊出生率は、「仮に年齢構造が同じであった場合」の出生率を、以下の方法で推定しています \\[\\frac{15歳の女性が産んだ子供の数}{15歳の女性の数} +..+ \\frac{49歳の女性が産んだ子供の数}{49歳の女性の数}\\]\nシンプルな枠組みであり、大規模なデータが活用可能な状況では、有効だと考えられます。 一方で、年齢以外の属性(教育歴、居住地等々)もバランスさせる場合、同じ属性を持つ事例数が少なくなり、適用が難しくなります。\n\n\n5.1.3 既存店ベースの比較\nバランス後の比較は、企業の経営戦略を考える上でも用いられます。 小売や飲食/宿泊業などでは、しばしば既存店に絞った上での、売上比較がなされます。 例えば、あるコンビニチェーンで、店舗あたりの平均売り上げが1000万円増大したとします。 同時に去年から今年にかけて、新規出店も大きく増加したとします。 新規店の方が売上が高くなる傾向がある場合、新規店割合の違いが、平均売上の上昇をもたらした可能性があります。\n既存店割合をバランスさせるシンプルな方法として、既存店のみに絞った平均売上を比較がよく行われます。 合計特殊出生率と同様に、新規店比率のみをバランスさせるのであれば、非常に実践的な方法です。 しかしながら他の属性、例えば客層の変化などもバランスさせたい場合は、事例数が不足する可能性が高くなります。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>把握を目的とする要約: Balanced Comparison</span>"
    ]
  },
  {
    "objectID": "complexcomparison.html#推定対象",
    "href": "complexcomparison.html#推定対象",
    "title": "5  把握を目的とする要約: Balanced Comparison",
    "section": "5.2 推定対象",
    "text": "5.2 推定対象\n\n5.2.1 バランス後の平均値\n以上の推定対象は、一般に以下のように定義できます。\nグループ \\(d\\) における \\(Y\\) の平均値は、一般に以下のように書き換えることができます。 \\[(d)におけるYの平均値\\] \\[=\\Biggr\\{(x\\ \\&\\ d)におけるYの平均値\\times (d)における(x)の割合\\Biggr\\}\\] \\[のxについての総和\\]\n\\(D\\) 間での平均差を生み出す要因は、以下に分解できます。\n\n\\(D\\) の間での\\(Y\\)の平均値の違い\n\\(D\\) の間での\\(X\\) の分布の違い\n\nバランス後の比較における推定対象は、\\(X\\) の分布の違いを排除したバランス後の平均値の差として定義します。 \\(d\\)のバランス後の平均値は、\\[(d)におけるYのバランス後平均値\\] \\[=\\Biggr\\{(x\\ \\&\\ d)におけるYの平均値\\times (x)へのウェイト\\Biggr\\}\\] \\[のxについての総和\\] バランス後の平均値の差は、\\(X\\) 内での平均差の\\((x)へのウェイト\\)を用いた集計値として書き換えることができます: \\[\\Biggr\\{\\Bigr[(x\\ \\&\\ D=1)におけるYの平均値-(x\\ \\&\\ D=0)におけるYの平均値\\Bigr]\\] \\[\\times  (x)へのウェイト\\Biggr\\}のxについての総和\\]\n\\((X=x)へのウェイト\\)は、原理的には研究者が設定できます。 以下、最も代表的なウェイトである、母集団全体での\\(X=x\\)の割合をウェイトとして、バランス後の平均値の推定を目指します。 因果推論においては、母集団全体での割合を用いた集計値を平均効果と呼んでおります。\n\n5.2.1.1 実例\n例えば、立地と取引年ごとの平均取引価格は以下です。\n\n\n\n\n\n\n\n\n平均価格\nCBD\nTradeYear\n事例割合\n\n\n\n\n37.7\n0\n2021\n0.784\n\n\n60.5\n1\n2021\n0.216\n\n\n39.2\n0\n2022\n0.779\n\n\n64.8\n1\n2022\n0.221\n\n\n\n\n\n\n\n2022/2021年の平均取引価格差は、データ全体では2.2 ですが、\\(CBD=1\\) では \\(64.8 - 60.5 =\\) 4.3、\\(CBD=0\\) では \\(39.2 - 37.7=\\) 1.4 となります。 よって立地をバランスさせた後の平均差は4.3 と 1.4 の”平均値”となります。 例えばデータ上での立地の割合、 CBD=1について0.22、CBD=0について0.78、をウェイトとして用いるのであれば 2 がバランス後の平均差となります。\n\n\n\n5.2.2 Balancing Weight\nバランス後の平均値は、Balancing weightを用いた加重平均としても計算できます。 バランス後の平均値を以下のように書き換えられることで、Balancing weight \\(\\omega(x)\\) は定義できます。\nバランス後の平均値 \\[(d)におけるYのバランス後平均値=\\Biggr\\{(x\\ \\&\\ d)におけるYの平均値\\] \\[\\times \\underbrace{\\frac{xへのウェイト}{dにおけるxの割合}}_{\\equiv\\omega(d,x)}\\times (d)における(x)の割合\\Biggr\\}\\] \\[のxについての総和\\]\nバランス後の平均値は、\\(D_i=d\\)を満たす事例についての加重平均としても算出できます。 \\[\\frac{D=1の事例についての\\omega(d)\\times Yの総和}{D=1を満たす事例数}\\] ただし\\(N\\)は全体の事例数、\\(I(D_i=d)\\)は事例\\(i\\)の\\(D\\)の値が\\(d\\)であれば1、それ以外であれば0となる変数です。よって\\(D_i=d\\)を満たす事例について、Balancing weightsを掛けたものの総和を計算し、\\(D_i=d\\)を満たす事例数で割ることで計算できます。\n例えば、\\((X=x)へのウェイト\\)としてCBD=1が0.22、CBD=0が0.78を用いるのであれば、Balancing Weightは以下のように算出できます。\n\n\n\n\n\n\n\n\n平均価格\nCBD\nTradeYear\n事例割合\nBalancing Weight\n\n\n\n\n37.7\n0\n2021\n0.41\n1.90\n\n\n60.5\n1\n2021\n0.11\n2.00\n\n\n39.2\n0\n2022\n0.37\n2.11\n\n\n64.8\n1\n2022\n0.11\n2.00\n\n\n\n\n\n\n\n\n\n5.2.3 仮定: Overlap\n母集団全体での\\(X=x\\)の割合をウェイトとした、バランス後の平均値を推定対象とするためには、母集団に対して以下を推定する必要があります。\n\n\n\n\n\n\nOverlapの仮定\n\n\n\n\n全ての\\(X\\)の組み合わせについて、\\(D=1\\)の事例も\\(D=0\\)の事例も、母集団上には両方存在する: \\[1 &gt; E[D|X] &gt;0\\] ただし \\(E[D|X]\\) は\\(D\\)の母平均(\\(D=1\\)の割合)\n\n\n\nPositivityが成り立っていない場合、\\(D=1\\) または \\(D=0\\) しか存在しない\\(X\\)の組み合わせが存在することになります。 結果、バランス後の比較は根本的に不可能です。 例えば、教育経験\\((=X)\\)をバランスさせた男女間\\((=D)\\)での賃金格差を推定したいとします。 ここで関心となる母集団は、男女間での教育経験の分断が極めて大きく、大学卒以上の女性は存在しないとします。 この場合、大学卒の女性割合は\\(0\\)であり、どのようなBalancing weight \\(\\omega(大学卒)\\) を用いたとしても、男性/女性の大学卒比率を揃えることは不可能です。 言い換えるならば、大学卒の女性が存在しないため、大学卒内で男女間の賃金を比較できないため、バランス後の比較は不可能です。\n@(有限標本ではOK?)\n((では?)、Positivityの不成立についての対処を論じます)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>把握を目的とする要約: Balanced Comparison</span>"
    ]
  },
  {
    "objectID": "complexcomparison.html#推定方法",
    "href": "complexcomparison.html#推定方法",
    "title": "5  把握を目的とする要約: Balanced Comparison",
    "section": "5.3 推定方法",
    "text": "5.3 推定方法\n\\(X\\)の組み合わせの種類に比べて、十分な事例数が存在するのであれば、Balancing weightは、データ上での\\(X\\)の割合を用いて計算できます。 この方法はExact MatchingやStratified Estimation (Wager 2024) として知られる方法による推定結果と完全に一致します。 例えばExact Matchingは、MatchIt package (Stuart et al. 2011) などを利用して実装できます。\nExact matchingやStratified Estimationは、非常に直感的な推定方法ですが、\\(X\\) の組み合わせが増えると、実行不可能です。 例えば\\(X\\)に、両親の年収や資産などの連続変数が含まれている場合は、\\(X\\)の組み合わせが非常に大きくなり、Balancing weightsを計算することは事実上不可能となります。\nこの問題を解決するために、次節以降で紹介する、OLSや傾向スコアの逆数(Inverse probability weights)の活用が有用です。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>把握を目的とする要約: Balanced Comparison</span>"
    ]
  },
  {
    "objectID": "complexcomparison.html#rによる実践例",
    "href": "complexcomparison.html#rによる実践例",
    "title": "5  把握を目的とする要約: Balanced Comparison",
    "section": "5.4 Rによる実践例",
    "text": "5.4 Rによる実践例\n\n以下のパッケージを使用\n\nreadr (tidyverseに同梱): データの読み込み\nmatchit: Exact matchingを含む多様なMatchingを実装\n\nmannual\n\n\n\n\n5.4.1 準備\nデータを取得します。 \\(D\\) として、中心6区かそれ以外で、1/0となる変数を定義します。 シンプルな比較分析について信頼区間は、データ分割は不要です。\n\nData = readr::read_csv(\"Public.csv\") # データ読み込み\n\nData = mutate(\n  Data,\n  D = if_else(\n    LargeDistrict == \"中心6区\",1,0\n  )\n)\n\n\n\n5.4.2 Balanced Weight\nMatchItパッケージ内のmatchti関数を用いて、Balanced weightsを計算します。 例えば立地別の平均取引価格とその信頼区間は、以下で計算できます。\n\nMatch = MatchIt::matchit(\n  D ~ Size + Tenure + StationDistance, # D ~ Xを指定\n  Data, # 用いるデータの指定\n  method = \"exact\", # Balanced weightを計算するために、exact matchingを実行\n  target = \"ATE\" # サンプル全体のXの分布をターゲット\n  )\n\nDataWeight = MatchIt::match.data(\n  Match, \n  drop.unmatched = FALSE # Balance weightが計算できない事例も含む\n  ) # Balance weightを含んだデータを生成 \n\nMatch # Balance weightの特徴を表示\n\nA matchit object\n - method: Exact matching\n - number of obs.: 6378 (original), 1702 (matched)\n - target estimand: ATT\n - covariates: Size, Tenure, StationDistance\n\n\nnumber of obs.において、元々の事例数 (6378) と balanced weightを計算できた事例数 (1702) を表示しています。 事例が大きく減少しており、balanced weightを計算できない事例が多かったことを示しています。 この理由は、Size, Tenure, StationDistanceが完全に一致する事例が、\\(D=1\\) または \\(D=0\\) のどちらかしか存在しない場合が多いためです。\nBalanced weightが算出できた事例について、バランス後の平均差を計算すると以下となります。\n\nlm(Price ~ D,\n   DataWeight,\n   weights = weights # Balancing weightsを使用\n   )\n\n\nCall:\nlm(formula = Price ~ D, data = DataWeight, weights = weights)\n\nCoefficients:\n(Intercept)            D  \n      36.05        12.55  \n\n\n単純比較の結果は以下であり、大きく異なることが確認できます。\n\nlm(Price ~ D,\n   DataWeight)\n\n\nCall:\nlm(formula = Price ~ D, data = DataWeight)\n\nCoefficients:\n(Intercept)            D  \n      38.04        20.94  \n\n\nただし今回のように、多くの事例が分析から除外されてしまった場合、単純比較とバランス後の平均差が乖離する理由は不明瞭です。 \\(X\\)をバランスさせることで平均差が変化した可能性がありますが、分析事例の限定も値を変化させます。 このため次節以降の方法を用いて、極力分析事例を除外しない方法を用いることが望ましいです。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>把握を目的とする要約: Balanced Comparison</span>"
    ]
  },
  {
    "objectID": "complexcomparison.html#reference",
    "href": "complexcomparison.html#reference",
    "title": "5  把握を目的とする要約: Balanced Comparison",
    "section": "5.5 Reference",
    "text": "5.5 Reference\n\n\n\n\nChattopadhyay, Ambarish, and José R. Zubizarreta. 2024. “Causation, Comparison, and Regression.” Harvard Data Science Review 6 (1).\n\n\nStuart, Elizabeth A, Gary King, Kosuke Imai, and Daniel Ho. 2011. “MatchIt: Nonparametric Preprocessing for Parametric Causal Inference.” Journal of Statistical Software.\n\n\nWager, Stefan. 2024. “Causal Inference: A Statistical Learning Approach.” preparation.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>把握を目的とする要約: Balanced Comparison</span>"
    ]
  },
  {
    "objectID": "whatif_moment.html",
    "href": "whatif_moment.html",
    "title": "6  Balancing Weightの推定: 特徴のバランス",
    "section": "",
    "text": "6.1 OLS\n近年の研究により、線型モデルのOLS推定は、Moment Balanceを達成することが確認されています (Imbens 2015; Chattopadhyay and Zubizarreta 2023)。 Chattopadhyay and Zubizarreta (2023) は、以下を証明しました。\nEquation 6.1 は、\\(X\\) の平均値を \\(D=\\{0,1\\}\\) 間で均質化していることを意味しています。 Equation 6.2 は、ウェイトとして総和を1に基準化しています。 すなわちStep 1において、平均値をバランスさせるウェイトの中から、最も分散が小さいものを選んでいることを意味しています。 Step 2において、このウェイトを用いた平均差を計算しています。\nウェイトの分散は、最終的な推定結果の推定誤差に影響を与えます。 一般に、ウェイトの分散が小さいと、推定誤差が削減される傾向があります。 OLSは、平均値のバランスを達成するウェイトから分散が最小となるものを選ぶため、推定誤差が小さくなる傾向を持ちます。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Balancing Weightの推定: 特徴のバランス</span>"
    ]
  },
  {
    "objectID": "whatif_moment.html#ols",
    "href": "whatif_moment.html#ols",
    "title": "6  Balancing Weightの推定: 特徴のバランス",
    "section": "",
    "text": "OLSの性質\n\n\n\n\n\\(D=\\{0,1\\}\\) であれば、統計モデル \\[Y\\sim\\beta_0 + \\beta_DD+\\beta_1X_1+..\\beta_LX_L\\] をOLS推定した得られる \\(\\beta_D\\) は一般に以下と一致します。 \\[\\beta_D=\\frac{D=1を満たす事例について(\\omega\\times Y)の総和}{D=1の事例数}\\] \\[- \\frac{D=0を満たす事例について(\\omega\\times Y)の総和}{D=0の事例数}\\] \\(\\omega\\)は、全ての\\(X=[X_1,..,X_L]\\) について、以下を満たすものが選ばれます。\n\n\\(X\\)の平均値のバランス: \\[\\frac{D=1を満たす事例について(\\omega\\times X_l)の総和}{D=1の事例数}\\] \\[= \\frac{D=0を満たす事例について(\\omega\\times X_l)の総和}{D=0の事例数} \\tag{6.1}\\]\nウエイトの総和と事例数の一致: \\[\\frac{D=1を満たす事例について\\omegaの総和}{D=1の事例数}\\] \\[=\\frac{D=0を満たす事例について\\omegaの総和}{D=0の事例数}\\] \\[=1 \\tag{6.2}\\]\nEquation 6.1 と Equation 6.2 を満たす \\(\\omega\\) のなかで、分散が最も小さくなる\n\n\n\n\n\n\n\n6.1.1 例\n部屋の広さ (Size) と 築年数 (Tenure) をバランスさせた後に、2022/2021年の平均取引価格差を推定します。 \\(Price\\sim D + Size + Tenure\\) をOLS回帰すると、以下のようなバランスが達成されます。\n\n\n\n\n\n\n\n\n\n赤点 (Unadjusted) は、バランス前の単純平均差を表します。 価格が大きく上昇していますが、取引物件の部屋の広さは狭くなり、築年数は古くなっています。 青点 (Adjusted)は、OLSによる暗黙のバランス後の差を示しています。 結果、SizeやTenureの平均値は完全にバランスしており、結果平均取引価格差も上昇しています。 Tenure2やSize2は、築年数や部屋の広さの二乗項(分散)、Tenure_Sizeは交差項(共分散)を示しており、これらについてはOLSを行ったとしてもバランスしていません。\n分散や共分散もバランスさせるためには、二乗項や交差項もモデルに導入したモデル \\(Price\\sim D + Size + Tenure + Size2 + Tenure2 + \\text{Tenure_Size}\\) をOLS推定します。 結果、以下の図の通り、分散や共分散もBalanceします。\n\n\n\n\n\n\n\n\n\n\n\n6.1.2 Post selection\nOLSにおいては、分布の特徴をどこまでバランスさせるのかが問題となります。 事例数が十分あれば、3乗項などの高次項もバランスさせることは可能です。 しかしながら事例数が少ない場合、大量のモーメントをバランスさせると、推定誤差が大きくなってしまいます。\nこのような問題に対して、OLS推定を行う前に重要な変数のみを選択することが必要となります。 変数選択を行う方法としては、Chernozhukov, Hansen, and Spindler (2015) がPost Double Selectionというデータ主導の手法を提案しており、幅広く応用されています。 Angrist and Frandsen (2022) は、変数選択について、より入門的な紹介を行っています。\nPost Double Selecctionでは、\\(X\\)の中から、\\(Y\\) または \\(D\\) について予測モデルを推定した際に使用される変数のみを使用し、OLS推定を行います。 予測モデルは、LASSOにより推定されます。 ここで“または”であることに注意してください。 例えば\\(Y\\) の予測モデルからは排除された変数であったとしても、\\(D\\)の予測モデルに利用されているのであれば、OLS推定に採用されます。 このような”慎重な”変数選択によって、信頼区間の計算可能性などの統計的性質を保証しています。\n当該手法はhdm packageを用いて実装できます。\n\nY = Data$Price # Outcome\nD = Data$D # Treatment\nX = select(\n  Data,\n  Size,\n  Size2,\n  Tenure,\n  Tenure2,\n  Tenure_Size) # Control\n\nFit = hdm::rlassoEffect(\n  x = as.matrix(X),\n  d = D,\n  y = Y\n) # Fit post double selection\n\nsummary(Fit) # Show results\n\n[1] \"Estimates and significance testing of the effect of target variables\"\n   Estimate. Std. Error t value Pr(&gt;|t|)    \nd1    3.8506     0.3304   11.65   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n選択された変数は、以下のように表示できます。 部屋の広さと築年数の平均値のみが、選択されたことが確認できます。\n\nFit$selection.index # Show selected X\n\n       Size       Size2      Tenure     Tenure2 Tenure_Size \n       TRUE       FALSE        TRUE       FALSE       FALSE",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Balancing Weightの推定: 特徴のバランス</span>"
    ]
  },
  {
    "objectID": "whatif_moment.html#olsの問題点と解決策",
    "href": "whatif_moment.html#olsの問題点と解決策",
    "title": "6  Balancing Weightの推定: 特徴のバランス",
    "section": "6.2 OLSの問題点と解決策",
    "text": "6.2 OLSの問題点と解決策\nOLSにより暗黙のうちに計算されるWeightは、平均値をバランスします Equation 6.1 。 しかしながら、Balancing weightsに求められる他の性質は必ずしも満たされません。\n\n6.2.1 解釈の難しさ\nバランス後の、\\(X\\) の平均値がどのような水準になるのか、一般に不透明です。 結果を解釈するためには、\\(X\\) の平均値は明確な水準、例えばデータ全体での平均値と一致させることが望ましいです。 しかしながら、OLSはそのような水準との一致を保証しません。\nOLSによるバランス後の\\(X\\)の平均値について、lmw packageにより診断できます。\n\n\n\n\n\n\n\n\n\n黒丸はOLSによるバランス後、ばつ印はバランス前の平均値を示しています。 Control groupは、\\(D=0\\) (2021年)、Treatment groupは、\\(D=1\\) (2022年)の値です。 0線は、サンプル平均を示しています。\n同図からバランス前は、2022年についてはSizeがサンプル平均よりも小さく、Tenureは長いことが確認できます。 黒丸を見ると、OLSによるバランス後はどちらも2022年と2021年の間で平均差がなくなることが確認できます。 ただし　０線からは乖離しており、サンプル平均とは一致していないことが確認できます。\n\n\n6.2.2 負の荷重\nBalancing weightsは、正の値を取ることが望まれます。 しかしながらOLSが生成するWeightは、負の値を取る可能性があり、ミスリーデイングな推定結果をもたらす可能性があります。\nlmw packageは、OLSが生成するweightsの値を計算します。 例えばhist関数により、ヒストグラムとして可視化できます。\n\n\n\n\n\n\n\n\n\n本応用例では、負のweightsは発生していないことが確認できました。\n\n\n6.2.3 解決策\n\\(D\\)と\\(X\\)の交差項を含めた以下のモデルを推定した、\\(\\beta_{D},..,\\beta_{DL}\\)の平均値は、サンプル全体の\\(X\\)の平均値とバランス後の平均値を一致させるWeightを活用した平均の差と一致します(Chattopadhyay and Zubizarreta 2023)。 \\[Y\\sim D\\times (\\beta_D + \\beta_{D1}X_1+..+\\beta_{DLX_L}) + \\beta_0 + \\beta_1X_1+..+\\beta_LX_L.\\] ただし負のweightは以前として生じる可能性があります。\n負のWeightを発生させない方法としては、Entropy weights (Hainmueller 2012) や Stable weights (Zubizarreta 2015) が有力です。 これらの手法では、サンプル平均との一致や正の値を取ることを条件として課した上で、weightを計算します。 このためOLSが持つ問題点の多くを克服しており、より信頼できるバランス後の比較分析が可能です。 これらの手法は WeightIt package (Greifer 2024) で容易に実装できます。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Balancing Weightの推定: 特徴のバランス</span>"
    ]
  },
  {
    "objectID": "whatif_moment.html#rによる実践例",
    "href": "whatif_moment.html#rによる実践例",
    "title": "6  Balancing Weightの推定: 特徴のバランス",
    "section": "6.3 Rによる実践例",
    "text": "6.3 Rによる実践例\n\n\\(D\\)と\\(X\\)の交差項を含めたモデルのOLS推定、およびその性質の診断は、以下のパッケージを用いて実装できます。\n\nreadr (tidyverseに同梱): データの読み込み\nlmw: OLSが計算するbalance weightsを計算\n\nRepository\n\nmarginaleffects: 交差項を含めたモデルでの推定\n\nMannual\n\n\n\n\n6.3.1 準備\nデータを取得します。 \\(D\\) として、中心6区かそれ以外で、1/0となる変数を定義します。 シンプルな比較分析について信頼区間は、データ分割は不要です。\n\nData = readr::read_csv(\"Public.csv\") # データ読み込み\n\nData = dplyr::mutate(\n  Data,\n  D = dplyr::if_else(\n    LargeDistrict == \"中心6区\",1,0\n  ) # 中心6区であれば1、それ以外であれば0\n)\n\n\n\n6.3.2 Balanced comparson by OLS\n交差項を含むOLSによりBalance させた推定結果は以下で導出できます。 Size,Tenure,StationDistanceの平均値、分散、共分散を、中心6区とそれ以外で一致させています\n\nOLS = lm(\n  Price ~ \n    D*(I(Size^2) + I(Tenure^2) + I(StationDistance^2) +\n         (Size + Tenure + StationDistance)**2) + # DとXの交差項\n    I(Size^2) + I(Tenure^2) + I(StationDistance^2) +\n               (Size + Tenure + StationDistance)**2, # X,\n  Data\n)\n\nmarginaleffects::avg_comparisons(\n  OLS, # 計算の元となるモデル\n  variables = \"D\", # Dについて平均差を推定\n  vcov = \"HC4\") # ロバストな信頼区間\n\n\n Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n     19.4      0.705 27.6   &lt;0.001 554.2  18.1   20.8\n\nTerm: D\nType:  response \nComparison: mean(1) - mean(0)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\nバランスさせない平均差(以下)と比べると、平均差が少し減少しています。\n\nestimatr::lm_robust(\n  Price ~ D,\n  Data\n)\n\n            Estimate Std. Error  t value     Pr(&gt;|t|) CI Lower CI Upper   DF\n(Intercept) 38.03972  0.3182179 119.5399 0.000000e+00 37.41591 38.66354 6376\nD           20.94057  1.2529064  16.7136 2.084367e-61 18.48446 23.39669 6376\n\n\n\n6.3.2.1 Balanced Weight\nlmw パッケージのlmw関数を用いれば、OLSが算出しているBalance weightsを計算できます。\n\nMatch = lmw::lmw(\n  ~ D + I(Size^2) + I(Tenure^2) + I(StationDistance^2) +\n               (Size + Tenure + StationDistance)**2, # 平均、分散、共分散をバランス\n  Data,\n  method = \"MRI\" # DとXの交差項を導入\n) # Weightの算出\n\nhist(Match$weights) # Weightのヒストグラムを算出\n\n\n\n\n\n\n\n\n少数ですが負のWeightが発生しています。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Balancing Weightの推定: 特徴のバランス</span>"
    ]
  },
  {
    "objectID": "whatif_moment.html#reference",
    "href": "whatif_moment.html#reference",
    "title": "6  Balancing Weightの推定: 特徴のバランス",
    "section": "6.4 Reference",
    "text": "6.4 Reference\n\n\n\n\nAngrist, Joshua D, and Brigham Frandsen. 2022. “Machine Labor.” Journal of Labor Economics 40 (S1): S97–140.\n\n\nChattopadhyay, Ambarish, Christopher H Hase, and José R Zubizarreta. 2020. “Balancing Vs Modeling Approaches to Weighting in Practice.” Statistics in Medicine 39 (24): 3227–54.\n\n\nChattopadhyay, Ambarish, and José R Zubizarreta. 2023. “On the Implied Weights of Linear Regression for Causal Inference.” Biometrika 110 (3): 615–29.\n\n\nChernozhukov, Victor, Christian Hansen, and Martin Spindler. 2015. “Valid Post-Selection and Post-Regularization Inference: An Elementary, General Approach.” Annu. Rev. Econ. 7 (1): 649–88.\n\n\nGreifer, Noah. 2024. WeightIt: Weighting for Covariate Balance in Observational Studies. https://ngreifer.github.io/WeightIt/.\n\n\nHainmueller, Jens. 2012. “Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies.” Political Analysis 20 (1): 25–46.\n\n\nImbens, Guido W. 2015. “Matching Methods in Practice: Three Examples.” Journal of Human Resources 50 (2): 373–419.\n\n\nZubizarreta, José R. 2015. “Stable Weights That Balance Covariates for Estimation with Incomplete Outcome Data.” Journal of the American Statistical Association 110 (511): 910–22.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Balancing Weightの推定: 特徴のバランス</span>"
    ]
  },
  {
    "objectID": "whatif_ps.html",
    "href": "whatif_ps.html",
    "title": "7  Balancing Weightの推定: 傾向スコア",
    "section": "",
    "text": "7.1 Inverse probability weighting\n\\((X=x)\\)へのウェイトとして、\\(X\\) の母分布をターゲットとするのであれば、Balancing weight \\(\\omega(X)\\) と傾向スコア \\(p_d(X)\\) の間に以下の関係性が成り立ちます。 \\[\\omega(X) = \\frac{D=dの割合}{p_d(X)}\\] よってバランス後の平均値は以下のように書き換えられます。 \\[\\frac{D=dについて(\\omega(X)\\times Y)の総和}{D=dの事例数}\\] \\[=\\frac{D=dについて[(D=dの割合/p_d(X))\\times Y]の総和}{D=dの割合\\times 総事例数}\\] \\[=\\frac{D=dについて[(1/p_d(X))\\times Y]の総和}{総事例数}\\] よって、傾向スコアが推定できれば、その逆数\\((1/p_d(X))\\) を掛ることでバランス後の平均値が推定できます。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Balancing Weightの推定: 傾向スコア</span>"
    ]
  },
  {
    "objectID": "whatif_ps.html#傾向スコアの推定方法",
    "href": "whatif_ps.html#傾向スコアの推定方法",
    "title": "7  Balancing Weightの推定: 傾向スコア",
    "section": "7.2 傾向スコアの推定方法",
    "text": "7.2 傾向スコアの推定方法\n傾向スコアの推定方法については、予測を目的とする要約 (Section 3) の手法を応用することができます。 例えば以下のモデルを、シンプルにOLSを用いて推定することも可能です。 \\[D\\sim\\beta_0+\\beta_1X_1+..\\] ただ多くの応用で、LogitやProbitなど、予測値が\\([0,1]\\) の範囲に収まることが保証される方法を用いることが多くなっています。\n近年では、より柔軟な推定手法 (LASSOやRandomForest, Boostingなどの機械学習の手法)を用いることが増えています。 既存の機械学習の手法が容易に応用できる点は、傾向スコアを用いることの大きな利点となります。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Balancing Weightの推定: 傾向スコア</span>"
    ]
  },
  {
    "objectID": "whatif_ps.html#問題点",
    "href": "whatif_ps.html#問題点",
    "title": "7  Balancing Weightの推定: 傾向スコア",
    "section": "7.3 問題点",
    "text": "7.3 問題点\nInverse probability weightingを用いたバランス後の平均値推定は、傾向スコアの推定精度に決定的に依存します。 シンプルなモデルをLogitなどで推定した場合、モデル定式化の誤りが深刻となりえます。 機械学習等のより柔軟な推定手法を用いれば、モデル定式化の誤りは減少します。 しかしながら、依然として推定精度は不十分な場合が多いことが知られています(Chernozhukov et al. 2018)1。\n以上の問題を克服するために、次節では \\(Y\\) の予測モデルも併用する推定方法 (Augmented inverse probability weighting) を紹介します。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Balancing Weightの推定: 傾向スコア</span>"
    ]
  },
  {
    "objectID": "whatif_ps.html#他の方法",
    "href": "whatif_ps.html#他の方法",
    "title": "7  Balancing Weightの推定: 傾向スコア",
    "section": "7.4 他の方法",
    "text": "7.4 他の方法\nここまでBalancing weightsを推定する方法として、OLSや傾向スコアを用いた方法を紹介しました。 他の有力な方法として、Imai and Ratkovic (2014) は、\\(X\\) のバランスと\\(p_d(X)\\)を極力両立するように推定する方法を提案しています。 Iacus, King, and Porro (2012), Huling and Mak (2024) では、\\(X\\) の分布の距離(Energy distance)を最小化するようにweightを推定します。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Balancing Weightの推定: 傾向スコア</span>"
    ]
  },
  {
    "objectID": "whatif_ps.html#reference",
    "href": "whatif_ps.html#reference",
    "title": "7  Balancing Weightの推定: 傾向スコア",
    "section": "7.5 Reference",
    "text": "7.5 Reference\n\n\n\n\nChernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. “Double/debiased machine learning for treatment and structural parameters.” The Econometrics Journal 21 (1): C1–68. https://doi.org/10.1111/ectj.12097.\n\n\nHuling, Jared D, and Simon Mak. 2024. “Energy Balancing of Covariate Distributions.” Journal of Causal Inference 12 (1): 20220029.\n\n\nIacus, Stefano M, Gary King, and Giuseppe Porro. 2012. “Causal Inference Without Balance Checking: Coarsened Exact Matching.” Political Analysis 20 (1): 1–24.\n\n\nImai, Kosuke, and Marc Ratkovic. 2014. “Covariate Balancing Propensity Score.” Journal of the Royal Statistical Society Series B: Statistical Methodology 76 (1): 243–63.\n\n\nRosenbaum, Paul R, and Donald B Rubin. 1983. “The Central Role of the Propensity Score in Observational Studies for Causal Effects.” Biometrika 70 (1): 41–55.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Balancing Weightの推定: 傾向スコア</span>"
    ]
  },
  {
    "objectID": "whatif_ps.html#footnotes",
    "href": "whatif_ps.html#footnotes",
    "title": "7  Balancing Weightの推定: 傾向スコア",
    "section": "",
    "text": "この問題は収束の遅さとして知られています↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Balancing Weightの推定: 傾向スコア</span>"
    ]
  },
  {
    "objectID": "whatif_argumentation.html",
    "href": "whatif_argumentation.html",
    "title": "8  Balanced Comparisonの改善: Augmentation",
    "section": "",
    "text": "8.1 動機\nバランス後の平均差の推定結果は、balancing weightsの推定精度に強く依存します。 例えば傾向スコアの逆数 (Chapter 7) を用いた推定では、傾向スコア(\\(D\\) の母平均)の高い精度での推定が必要ですが、実践は困難です。 \\(D\\)のモデルを、Logitなどの伝統的な方法で推定する場合、研究者が事前に設定するモデルの定式化に推定結果が強く依存します。 LASSOなどより柔軟な推定方法を用いると、モデルへの依存度は低下させられますが、データへの依存度は上昇してしまいます。 このためより推定結果が不安定になりやすく、例えば信頼区間の計算 (Chapter 4) などが困難になります。\nBalancing weightsの推定結果への依存度を下げる方法として、\\(Y\\) のモデルを用いた補強 (Augment) が提案されています (Ben-Michael et al. 2021)。 このような手法は、特に機械学習を用いた推定との相性が良く、近年改めて注目されています(Chernozhukov et al. 2018)。 以下では補強を行なった推定値として、Augmented Inverse Probability Weight (Robins and Rotnitzky 1995) を紹介します。",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Balanced Comparisonの改善: Augmentation</span>"
    ]
  },
  {
    "objectID": "whatif_argumentation.html#augmented-inverse-probability-weighting",
    "href": "whatif_argumentation.html#augmented-inverse-probability-weighting",
    "title": "8  Balanced Comparisonの改善: Augmentation",
    "section": "8.2 Augmented Inverse Probability Weighting",
    "text": "8.2 Augmented Inverse Probability Weighting\n\n\n\n\n\n\nAugmented Inverse Probability Weightingの定義\n\n\n\n\nバランス後の平均値は、以下の通り推定できます。 \\[\\underbrace{\\frac{\\biggr[(1/p_d(X))\\times Y\\biggr] のD=dについての総和}{D=dの事例数}}_{Inverse\\ probability\\ weighting}\\] \\[+\\underbrace{\\frac{\\biggr[[(p_{d}(X) - D]/p_d(X))\\times f(D=d,X)\\biggr]の総和}{事例数}}_{補強}\\] ただし \\(f(D=d,X)\\) は \\(Y\\) の予測値, \\(p_{d}(X)\\) は傾向スコアの推定値です。\n\n\n\nAugmented inverse probability weighting はいくつかの利点を持ちます。 実践上の大きな利点は、\\(Y\\)や\\(D\\)の予測モデル \\((f(D,X),p_d(X))\\) 推定に機械学習を利用できることです。\n\n\\(Y\\)や\\(D\\) の予測値 \\(f(D,X)\\) や \\(p_d(X)\\) は、母平均の一致推定量である必要があります。 一致推定量とは、無限大の事例数で推定できた場合、予測値と母平均が一致する推定値のことです。この要求は、機械学習を活用することで比較的緩やかな仮定のもとで保証されます。\n機械学習の弱点である、モデルがデータにより依存していまう、という問題についても、その弊害を軽減できます。 限られた事例数のもとで、\\(f(D,X)\\) や \\(p_d(X)\\) の推定誤差が十分に削減できなかったとしても、それらを用いて推定されるバランス後の平均値は、より高い精度で推定でき、信頼区間も計算できます。これは\\(Y\\)と\\(D\\)の予測モデルの内、どちらか一方の推定精度が不十分であったとしても、バランス後の平均値の推定結果が大きな影響を受けないように設計されているためです。\n\n\\(f(D,X),p_d(X)\\)をOLSやLogit、LASSOなどで推定する場合、Augmented Inverse Probability Weightを用いた推定値は、以下のような性質を持ちます。\n\n\n\n\n\n\nAugmented Inverse Probability Weightingの性質\n\n\n\n\n以下の仮定のもとで、Augmented Inverse Probability Weightを用いた推定値について、信頼区間が計算できる\n\n仮定1. Overlapが成り立つ\n仮定2. \\(f(D,X),p_d(X)\\) の推定精度は、ある程度高い\n仮定3. \\(f(D,X),p_d(X)\\) は、交差推定で推定されている\n\n\n仮定1 (Posivitiy)は、バランス後の比較の根本的な仮定であり、推定方法に拘らず必要です。\n仮定2 が要求する推定精度を保証することは、厳密には困難です。 このため実用においては、さまざまな推定方法 (OLS,LASSOなど)の予測精度をデータ分割 (Chapter 3) などで検証し、最善の方法を用いる必要があります。\n仮定3が要求する交差推定は、以下の手順で実行できます。\n\n8.2.1 交差推定\nある事例 \\(i\\) について、予測値を算出する予測モデルは、当該事例\\(i\\)を用いずに推定される必要があります。 このような推定を効率的に行う方法として、交差推定 (Cross fitting)が頻繁に用いられます。\n\n\n\n\n\n\n交差推定\n\n\n\n\n事例をランダムにいくつかのグループ (第1,..,Kグループ)\n第１グループに対する予測値を算出する。その際に用いる予測モデルは、第１グループ以外の事例を用いて推定する。\n第２グループについて、手順２を繰り返し、全事例に対して予測値を算出する。\n第３グループ以降についても、順次、手順２を繰り返す",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Balanced Comparisonの改善: Augmentation</span>"
    ]
  },
  {
    "objectID": "whatif_argumentation.html#rによる実践例",
    "href": "whatif_argumentation.html#rによる実践例",
    "title": "8  Balanced Comparisonの改善: Augmentation",
    "section": "8.3 Rによる実践例",
    "text": "8.3 Rによる実践例\nAhrens et al. (2024) の手法を実装します。\n\n以下のパッケージを使用\n\nreadr (tidyverseに同梱): データの読み込み\nddml: Augmented Inverse Probability Weightingの実装\n\n\n\n8.3.1 準備\nデータを取得します。 \\(D\\) として、中心6区かそれ以外で、1/0となる変数を定義します。 シンプルな比較分析について信頼区間は、データ分割は不要です。\n\nData = readr::read_csv(\"Public.csv\") # データ読み込み\n\nData = dplyr::mutate(\n  Data,\n  D = dplyr::if_else(\n    LargeDistrict == \"中心6区\",1,0\n  ) # 中心6区であれば1、それ以外であれば0\n) # Dの定義\n\nY = Data$Price\nD = Data$D\nX = model.matrix(\n  ~ 0 + poly(Size,2) + poly(Tenure,2) + poly(StationDistance,2),\n  Data\n)\nX = scale(X)\n\n\n\n8.3.2 Balanced comparson by OLS\n\nATE = ddml::ddml_ate(\n  y = Y,\n  D = D,\n  X = X,\n  learners = list(\n    list(fun = ddml::mdl_glmnet)\n  ),\n  shortstack = TRUE,\n  sample_folds = 2,\n  silent = TRUE\n)\n\nATE$oos_pred$ED_X |&gt; summary()\n\n      nnls         \n Min.   :-0.01351  \n 1st Qu.: 0.15354  \n Median : 0.22826  \n Mean   : 0.22321  \n 3rd Qu.: 0.29270  \n Max.   : 0.50790  \n\nATE |&gt; summary()\n\nATE estimation results: \n \n     Estimate Std. Error t value  Pr(&gt;|t|)\nnnls     20.9      0.779    26.8 2.08e-158",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Balanced Comparisonの改善: Augmentation</span>"
    ]
  },
  {
    "objectID": "whatif_argumentation.html#reference",
    "href": "whatif_argumentation.html#reference",
    "title": "8  Balanced Comparisonの改善: Augmentation",
    "section": "8.4 Reference",
    "text": "8.4 Reference\n\n\n\n\nAhrens, Achim, Christian B Hansen, Mark E Schaffer, and Thomas Wiemann. 2024. “Model Averaging and Double Machine Learning.” arXiv Preprint arXiv:2401.01645.\n\n\nBen-Michael, Eli, Avi Feller, David A Hirshberg, and José R Zubizarreta. 2021. “The Balancing Act in Causal Inference.” arXiv Preprint arXiv:2110.14831.\n\n\nChernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. “Double/debiased machine learning for treatment and structural parameters.” The Econometrics Journal 21 (1): C1–68. https://doi.org/10.1111/ectj.12097.\n\n\nRobins, James M., and Andrea Rotnitzky. 1995. “Semiparametric Efficiency in Multivariate Regression Models with Missing Data.” Journal of the American Statistical Association 90 (429): 122129. https://doi.org/10.1080/01621459.1995.10476494.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Balanced Comparisonの改善: Augmentation</span>"
    ]
  }
]